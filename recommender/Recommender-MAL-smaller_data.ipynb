{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0TIzX0K6b0i"
      },
      "source": [
        "# <center> Recommender System </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT9Y0Ah56b0k"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKd9UomS6b0k"
      },
      "source": [
        "Connect to drive (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltqyg7vA6b0k",
        "outputId": "f9d502cb-abd4-47a0-e7f5-4553dbbc4db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "DRIVE_DIR = \"\"\n",
        "USING_DRIVE = False\n",
        "if USING_DRIVE:\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    DRIVE_DIR = \"drive/My Drive/Bangkit/\"\n",
        "\n",
        "# Check GPU\n",
        "devices = tf.config.experimental.list_physical_devices()\n",
        "for device in devices:\n",
        "    print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "polD1-8m6b0l"
      },
      "source": [
        "Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dHM-Im3g6b0l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "LOG_NAME = \"recommender-small-simplerr\"\n",
        "REMARK = \"Try current best model 128batch\"\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 1e-6\n",
        "EPOCH = 300\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "LOSS_FN = tf.keras.losses.MeanAbsoluteError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUCIib5V6b0m"
      },
      "source": [
        "Log dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NgTRDLlo6b0m"
      },
      "outputs": [
        {
          "ename": "FileExistsError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m SUMMARY_DIR \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DRIVE_DIR, \u001b[39m\"\u001b[39m\u001b[39mlog/model/summary/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m (os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MODEL_DIR, LOG_NAME)) \u001b[39mor\u001b[39;00m \n\u001b[0;32m      8\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(KERAS_DIR, LOG_NAME)) \u001b[39mor\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(PLOT_DIR, LOG_NAME)) \u001b[39mor\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(SUMMARY_DIR, LOG_NAME)) \u001b[39mor\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DETAIL_DIR, LOG_NAME))):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m\n",
            "\u001b[1;31mFileExistsError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "DETAIL_DIR = os.path.join(DRIVE_DIR, \"log/detail/\")\n",
        "MODEL_DIR = os.path.join(DRIVE_DIR, \"log/model/savedmodel/\")\n",
        "KERAS_DIR = os.path.join(DRIVE_DIR, \"log/model/keras/\")\n",
        "PLOT_DIR = os.path.join(DRIVE_DIR, \"log/plot\")\n",
        "SUMMARY_DIR = os.path.join(DRIVE_DIR, \"log/model/summary/\")\n",
        "\n",
        "if (os.path.exists(os.path.join(MODEL_DIR, LOG_NAME)) or \n",
        "    os.path.exists(os.path.join(KERAS_DIR, LOG_NAME)) or\n",
        "    os.path.exists(os.path.join(PLOT_DIR, LOG_NAME)) or\n",
        "    os.path.exists(os.path.join(SUMMARY_DIR, LOG_NAME)) or\n",
        "    os.path.exists(os.path.join(DETAIL_DIR, LOG_NAME))):\n",
        "    raise FileExistsError\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUx0u7wS6b0m"
      },
      "source": [
        "## Data Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKdozaq36b0m"
      },
      "source": [
        "### Load data from CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adJLSdQH6b0n"
      },
      "source": [
        "Not using user data for a while"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWimNAkh6b0n"
      },
      "source": [
        "Data is generated randomly using Excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOY5h8C16b0n"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = os.path.join(DRIVE_DIR, \"data/synt_data_smaller_dataset/\")\n",
        "INFLUENCER_FILE = os.path.join(DATA_DIR, \"data_content_influencer_categ.csv\")\n",
        "OWNER_FILE = os.path.join(DATA_DIR, \"data_content_owner_categ.csv\")\n",
        "HISTORY_FILE = os.path.join(DATA_DIR, \"historical_data.csv\")\n",
        "\n",
        "df_influencer = pd.read_csv(INFLUENCER_FILE)\n",
        "# df_owner = pd.read_csv(OWNER_FILE)\n",
        "df_history = pd.read_csv(HISTORY_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9FQwofA6b0n"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pRduYuFh6b0n",
        "outputId": "efa0a603-b46e-4beb-a15e-fcac12e66703"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>insta_follower</th>\n",
              "      <th>tiktok</th>\n",
              "      <th>youtube</th>\n",
              "      <th>categories</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>6018900</td>\n",
              "      <td>8078640</td>\n",
              "      <td>15046770</td>\n",
              "      <td>Category 8,Category 2</td>\n",
              "      <td>9.37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82</td>\n",
              "      <td>23809950</td>\n",
              "      <td>35177250</td>\n",
              "      <td>44279670</td>\n",
              "      <td>Category 4,Category 2,Category 1,Category 8,Ca...</td>\n",
              "      <td>9.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>296</td>\n",
              "      <td>3427860</td>\n",
              "      <td>5198670</td>\n",
              "      <td>5264340</td>\n",
              "      <td>Category 6,Category 1,Category 4,Category 5</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>127</td>\n",
              "      <td>20207160</td>\n",
              "      <td>38229630</td>\n",
              "      <td>74752350</td>\n",
              "      <td>Category 7,Category 6</td>\n",
              "      <td>9.17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137</td>\n",
              "      <td>4537980</td>\n",
              "      <td>8215080</td>\n",
              "      <td>13298910</td>\n",
              "      <td>Category 6,Category 1,Category 4,Category 5</td>\n",
              "      <td>9.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  insta_follower    tiktok   youtube  \\\n",
              "0  1723         6018900   8078640  15046770   \n",
              "1    82        23809950  35177250  44279670   \n",
              "2   296         3427860   5198670   5264340   \n",
              "3   127        20207160  38229630  74752350   \n",
              "4   137         4537980   8215080  13298910   \n",
              "\n",
              "                                          categories  avg_rating  pricing_LOW  \\\n",
              "0                              Category 8,Category 2        9.37            0   \n",
              "1  Category 4,Category 2,Category 1,Category 8,Ca...        9.26            0   \n",
              "2        Category 6,Category 1,Category 4,Category 5        9.25            0   \n",
              "3                              Category 7,Category 6        9.17            0   \n",
              "4        Category 6,Category 1,Category 4,Category 5        9.16            0   \n",
              "\n",
              "   pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  pricing_HIGH  \n",
              "0                  0            1                  1             1  \n",
              "1                  0            1                  1             1  \n",
              "2                  0            1                  1             0  \n",
              "3                  0            1                  1             1  \n",
              "4                  0            1                  1             1  "
            ]
          },
          "execution_count": 611,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_influencer.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EgUvt646b0n",
        "outputId": "02a5b9c0-f6b9-4a29-edee-b43d0b15e10f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3532 entries, 0 to 3531\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 3532 non-null   int64  \n",
            " 1   insta_follower     3532 non-null   int64  \n",
            " 2   tiktok             3532 non-null   int64  \n",
            " 3   youtube            3532 non-null   int64  \n",
            " 4   categories         3532 non-null   object \n",
            " 5   avg_rating         3532 non-null   float64\n",
            " 6   pricing_LOW        3532 non-null   int64  \n",
            " 7   pricing_BELOW_AVG  3532 non-null   int64  \n",
            " 8   pricing_AVG        3532 non-null   int64  \n",
            " 9   pricing_ABOVE_AVG  3532 non-null   int64  \n",
            " 10  pricing_HIGH       3532 non-null   int64  \n",
            "dtypes: float64(1), int64(9), object(1)\n",
            "memory usage: 303.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df_influencer.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "t-gTa4GC6b0o",
        "outputId": "de289730-abaa-4205-c12b-ff2166c46796"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>insta_follower</th>\n",
              "      <th>tiktok</th>\n",
              "      <th>youtube</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3532.000000</td>\n",
              "      <td>3.532000e+03</td>\n",
              "      <td>3.532000e+03</td>\n",
              "      <td>3.532000e+03</td>\n",
              "      <td>3532.000000</td>\n",
              "      <td>3532.000000</td>\n",
              "      <td>3532.000000</td>\n",
              "      <td>3532.000000</td>\n",
              "      <td>3532.000000</td>\n",
              "      <td>3532.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2078.235844</td>\n",
              "      <td>1.739045e+06</td>\n",
              "      <td>2.459950e+06</td>\n",
              "      <td>3.416828e+06</td>\n",
              "      <td>7.292537</td>\n",
              "      <td>0.328426</td>\n",
              "      <td>0.488675</td>\n",
              "      <td>0.416761</td>\n",
              "      <td>0.161665</td>\n",
              "      <td>0.114949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1403.980694</td>\n",
              "      <td>2.683461e+06</td>\n",
              "      <td>4.010099e+06</td>\n",
              "      <td>5.794205e+06</td>\n",
              "      <td>0.662597</td>\n",
              "      <td>0.469707</td>\n",
              "      <td>0.499943</td>\n",
              "      <td>0.493092</td>\n",
              "      <td>0.368195</td>\n",
              "      <td>0.319006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.136000e+04</td>\n",
              "      <td>5.031000e+04</td>\n",
              "      <td>5.532000e+04</td>\n",
              "      <td>2.370000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>900.750000</td>\n",
              "      <td>3.462900e+05</td>\n",
              "      <td>4.563300e+05</td>\n",
              "      <td>6.102900e+05</td>\n",
              "      <td>6.860000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1884.500000</td>\n",
              "      <td>7.468650e+05</td>\n",
              "      <td>1.034235e+06</td>\n",
              "      <td>1.428285e+06</td>\n",
              "      <td>7.330000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3120.500000</td>\n",
              "      <td>1.970962e+06</td>\n",
              "      <td>2.658832e+06</td>\n",
              "      <td>3.725685e+06</td>\n",
              "      <td>7.730000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6227.000000</td>\n",
              "      <td>3.041751e+07</td>\n",
              "      <td>4.039176e+07</td>\n",
              "      <td>7.475235e+07</td>\n",
              "      <td>9.370000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id  insta_follower        tiktok       youtube   avg_rating  \\\n",
              "count  3532.000000    3.532000e+03  3.532000e+03  3.532000e+03  3532.000000   \n",
              "mean   2078.235844    1.739045e+06  2.459950e+06  3.416828e+06     7.292537   \n",
              "std    1403.980694    2.683461e+06  4.010099e+06  5.794205e+06     0.662597   \n",
              "min       1.000000    5.136000e+04  5.031000e+04  5.532000e+04     2.370000   \n",
              "25%     900.750000    3.462900e+05  4.563300e+05  6.102900e+05     6.860000   \n",
              "50%    1884.500000    7.468650e+05  1.034235e+06  1.428285e+06     7.330000   \n",
              "75%    3120.500000    1.970962e+06  2.658832e+06  3.725685e+06     7.730000   \n",
              "max    6227.000000    3.041751e+07  4.039176e+07  7.475235e+07     9.370000   \n",
              "\n",
              "       pricing_LOW  pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  \\\n",
              "count  3532.000000        3532.000000  3532.000000        3532.000000   \n",
              "mean      0.328426           0.488675     0.416761           0.161665   \n",
              "std       0.469707           0.499943     0.493092           0.368195   \n",
              "min       0.000000           0.000000     0.000000           0.000000   \n",
              "25%       0.000000           0.000000     0.000000           0.000000   \n",
              "50%       0.000000           0.000000     0.000000           0.000000   \n",
              "75%       1.000000           1.000000     1.000000           0.000000   \n",
              "max       1.000000           1.000000     1.000000           1.000000   \n",
              "\n",
              "       pricing_HIGH  \n",
              "count   3532.000000  \n",
              "mean       0.114949  \n",
              "std        0.319006  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        0.000000  \n",
              "max        1.000000  "
            ]
          },
          "execution_count": 613,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_influencer.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y5wNWPbA6b0o",
        "outputId": "4cefa513-c9b5-42c7-d5ad-b46838a373fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>sentiment_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   own_id  inf_id  star_rating  sentiment_rating\n",
              "0       2      12            5              1.00\n",
              "1       2      13            4              0.71\n",
              "2       2      14            4              0.71\n",
              "3       2      15            4              0.69\n",
              "4       2      16            4              0.87"
            ]
          },
          "execution_count": 614,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOa8c6Bx6b0o",
        "outputId": "04f2e6e9-6637-428c-b5f1-8bc09848c8bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 152893 entries, 0 to 152892\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   own_id            152893 non-null  int64  \n",
            " 1   inf_id            152893 non-null  int64  \n",
            " 2   star_rating       152893 non-null  int64  \n",
            " 3   sentiment_rating  152893 non-null  float64\n",
            "dtypes: float64(1), int64(3)\n",
            "memory usage: 4.7 MB\n"
          ]
        }
      ],
      "source": [
        "df_history.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "TBs_bu7J6b0o",
        "outputId": "2888c4cb-86a7-4e81-bade-ee1f375e1c79"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>sentiment_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>152893.000000</td>\n",
              "      <td>152893.000000</td>\n",
              "      <td>152893.000000</td>\n",
              "      <td>152893.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2393.766288</td>\n",
              "      <td>1203.203626</td>\n",
              "      <td>4.005932</td>\n",
              "      <td>0.750553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1444.328510</td>\n",
              "      <td>1086.898864</td>\n",
              "      <td>0.804511</td>\n",
              "      <td>0.164894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1077.000000</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2403.000000</td>\n",
              "      <td>866.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3692.000000</td>\n",
              "      <td>1763.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4975.000000</td>\n",
              "      <td>6227.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              own_id         inf_id    star_rating  sentiment_rating\n",
              "count  152893.000000  152893.000000  152893.000000     152893.000000\n",
              "mean     2393.766288    1203.203626       4.005932          0.750553\n",
              "std      1444.328510    1086.898864       0.804511          0.164894\n",
              "min         2.000000       1.000000       1.000000          0.000000\n",
              "25%      1077.000000     380.000000       4.000000          0.650000\n",
              "50%      2403.000000     866.000000       4.000000          0.760000\n",
              "75%      3692.000000    1763.000000       5.000000          0.870000\n",
              "max      4975.000000    6227.000000       5.000000          1.000000"
            ]
          },
          "execution_count": 616,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVn8QMc76b0o"
      },
      "source": [
        "## Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N30NlTAl6b0o"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rED6Pt5Z6b0o"
      },
      "source": [
        "#### Missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1XQOSWt6b0p",
        "outputId": "617ba75e-7c49-45b5-d531-4fe5f96010be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                   0\n",
              "insta_follower       0\n",
              "tiktok               0\n",
              "youtube              0\n",
              "categories           0\n",
              "avg_rating           0\n",
              "pricing_LOW          0\n",
              "pricing_BELOW_AVG    0\n",
              "pricing_AVG          0\n",
              "pricing_ABOVE_AVG    0\n",
              "pricing_HIGH         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 617,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_influencer.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MOCkxUR6b0p",
        "outputId": "9c983da4-5da7-4441-c403-dafa45460db3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "own_id              0\n",
              "inf_id              0\n",
              "star_rating         0\n",
              "sentiment_rating    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 618,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wLwW20o6b0p"
      },
      "source": [
        "No missing value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ2RmTtz6b0p"
      },
      "source": [
        "#### Irrelevant Data / Invalid Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS7foeoW6b0p"
      },
      "source": [
        "Check if all history has valid influencer and owner ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3I9fBI36b0p",
        "outputId": "3d0cddab-1eef-499a-9bb9-46099510f6d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 619,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history[\"inf_id\"].isin(df_influencer[\"id\"]).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us63TR4M6b0p"
      },
      "source": [
        "All history data has valid influencer and owner ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV8kcF2x6b0p"
      },
      "source": [
        "### Data Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyNya-nr6b0p"
      },
      "source": [
        "Normalize influencer data: Scale follower count and One-hot categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfHCwe6a6b0q"
      },
      "outputs": [],
      "source": [
        "def one_hot(df, column):\n",
        "    one_hot = df[column].str.get_dummies()\n",
        "    col_name = one_hot.columns\n",
        "    new_name = list(map(lambda name: column + \"_\" + name, col_name))\n",
        "    one_hot.rename(columns={k: v for k, v in zip(col_name, new_name)}, inplace=True)\n",
        "\n",
        "    df = pd.concat([df, one_hot], axis=1)\n",
        "    df = df.drop(column, axis=1)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "CpLHbZc_6b0q",
        "outputId": "597f0425-9cef-44f8-a974-b07251670b65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 8</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>0.937</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82</td>\n",
              "      <td>0.926</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>296</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>127</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  avg_rating  pricing_LOW  pricing_BELOW_AVG  pricing_AVG  \\\n",
              "0  1723       0.937            0                  0            1   \n",
              "1    82       0.926            0                  0            1   \n",
              "2   296       0.925            0                  0            1   \n",
              "3   127       0.917            0                  0            1   \n",
              "4   137       0.916            0                  0            1   \n",
              "\n",
              "   pricing_ABOVE_AVG  pricing_HIGH  Category 1  Category 10  Category 2  ...  \\\n",
              "0                  1             1           0            0           1  ...   \n",
              "1                  1             1           1            0           1  ...   \n",
              "2                  1             0           1            0           0  ...   \n",
              "3                  1             1           0            0           0  ...   \n",
              "4                  1             1           1            0           0  ...   \n",
              "\n",
              "   Category 8  Category 9  youtube_High  youtube_Low  youtube_Medium  \\\n",
              "0           1           0             1            0               0   \n",
              "1           1           0             1            0               0   \n",
              "2           0           0             1            0               0   \n",
              "3           0           0             1            0               0   \n",
              "4           0           0             1            0               0   \n",
              "\n",
              "   tiktok_High  tiktok_Low  tiktok_Medium  insta_follower_High  \\\n",
              "0            1           0              0                    1   \n",
              "1            1           0              0                    1   \n",
              "2            1           0              0                    1   \n",
              "3            1           0              0                    1   \n",
              "4            1           0              0                    1   \n",
              "\n",
              "   insta_follower_Medium  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "execution_count": 621,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "YOUTUBE_HIGH_THRES = 2_000_000\n",
        "YOUTUBE_LOW_THRES = 100_000\n",
        "TIKTOK_HIGH_THRES = 2_000_000\n",
        "TIKTOK_LOW_THRES = 100_000\n",
        "INSTAGRAM_HIGH_THRES = 1_000_000\n",
        "INSTAGRAM_LOW_THRES = 50_000\n",
        "\n",
        "# follower_scaler = MinMaxScaler()\n",
        "\n",
        "df_inf_norm = df_influencer.copy()\n",
        "df_inf_norm['avg_rating'] = df_inf_norm[['avg_rating']] / 10\n",
        "# df_inf_norm[[\"insta_follower\", \"tiktok\", \"youtube\"]] = follower_scaler.fit_transform(df_inf_norm[[\"insta_follower\", \"tiktok\", \"youtube\"]])\n",
        "\n",
        "# df_inf_norm = one_hot(df_inf_norm, 'price_category') \n",
        "\n",
        "one_hot_categories = df_inf_norm['categories'].str.get_dummies(sep=',')\n",
        "df_inf_norm = pd.concat([df_inf_norm, one_hot_categories], axis=1)\n",
        "df_inf_norm = df_inf_norm.drop('categories', axis=1)\n",
        "\n",
        "youtube_bin = [0, YOUTUBE_LOW_THRES, YOUTUBE_HIGH_THRES, df_inf_norm['youtube'].max()]\n",
        "tiktok_bin = [0, TIKTOK_LOW_THRES, TIKTOK_HIGH_THRES, df_inf_norm['tiktok'].max()]\n",
        "insta_bin = [0, INSTAGRAM_LOW_THRES, INSTAGRAM_HIGH_THRES, df_inf_norm['insta_follower'].max()]\n",
        "\n",
        "df_inf_norm['youtube'] = pd.cut(df_inf_norm['youtube'],bins=youtube_bin, labels=[\"Low\", \"Medium\", \"High\"])  \n",
        "df_inf_norm = one_hot(df_inf_norm, 'youtube') \n",
        "\n",
        "df_inf_norm['tiktok'] = pd.cut(df_inf_norm['tiktok'],bins=tiktok_bin, labels=[\"Low\", \"Medium\", \"High\"])  \n",
        "df_inf_norm = one_hot(df_inf_norm, 'tiktok') \n",
        "\n",
        "df_inf_norm['insta_follower'] = pd.cut(df_inf_norm['insta_follower'],bins=insta_bin, labels=[\"Low\", \"Medium\", \"High\"])  \n",
        "df_inf_norm = one_hot(df_inf_norm, 'insta_follower') \n",
        "\n",
        "df_inf_norm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcb1BIyd6b0q"
      },
      "source": [
        "Combine star and sentiment rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DVaCP1n-6b0q",
        "outputId": "1c75bd32-5079-4ea1-94ac-efca455f8e71"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>sentiment_rating</th>\n",
              "      <th>combined_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152888</th>\n",
              "      <td>4975</td>\n",
              "      <td>546</td>\n",
              "      <td>4</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152889</th>\n",
              "      <td>4975</td>\n",
              "      <td>408</td>\n",
              "      <td>5</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152890</th>\n",
              "      <td>4975</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152891</th>\n",
              "      <td>4975</td>\n",
              "      <td>874</td>\n",
              "      <td>4</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152892</th>\n",
              "      <td>4975</td>\n",
              "      <td>879</td>\n",
              "      <td>4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152893 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        own_id  inf_id  star_rating  sentiment_rating  combined_rating\n",
              "0            2      12            5              1.00            1.000\n",
              "1            2      13            4              0.71            0.764\n",
              "2            2      14            4              0.71            0.764\n",
              "3            2      15            4              0.69            0.756\n",
              "4            2      16            4              0.87            0.828\n",
              "...        ...     ...          ...               ...              ...\n",
              "152888    4975     546            4              0.77            0.788\n",
              "152889    4975     408            5              0.95            0.980\n",
              "152890    4975     158            4              0.88            0.832\n",
              "152891    4975     874            4              0.83            0.812\n",
              "152892    4975     879            4              0.70            0.760\n",
              "\n",
              "[152893 rows x 5 columns]"
            ]
          },
          "execution_count": 622,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "STAR_WEIGHT = 0.6\n",
        "SENTIMENT_WEIGHT = 0.4\n",
        "\n",
        "df_history[\"combined_rating\"] = STAR_WEIGHT * df_history[\"star_rating\"] / 5 + SENTIMENT_WEIGHT * df_history[\"sentiment_rating\"]\n",
        "df_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "B-Q_KqeL6b0q",
        "outputId": "c2f11855-ee72-4abd-abae-a0d9ba95defd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>sentiment_rating</th>\n",
              "      <th>combined_rating</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>star_rating</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1485</td>\n",
              "      <td>1485</td>\n",
              "      <td>1485</td>\n",
              "      <td>1485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4528</td>\n",
              "      <td>4528</td>\n",
              "      <td>4528</td>\n",
              "      <td>4528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26534</td>\n",
              "      <td>26534</td>\n",
              "      <td>26534</td>\n",
              "      <td>26534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>79394</td>\n",
              "      <td>79394</td>\n",
              "      <td>79394</td>\n",
              "      <td>79394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>40952</td>\n",
              "      <td>40952</td>\n",
              "      <td>40952</td>\n",
              "      <td>40952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             own_id  inf_id  sentiment_rating  combined_rating\n",
              "star_rating                                                   \n",
              "1              1485    1485              1485             1485\n",
              "2              4528    4528              4528             4528\n",
              "3             26534   26534             26534            26534\n",
              "4             79394   79394             79394            79394\n",
              "5             40952   40952             40952            40952"
            ]
          },
          "execution_count": 623,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rating_count = df_history.groupby(\"star_rating\").count()\n",
        "rating_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "HC9K0tAC6b0q",
        "outputId": "468ee171-bfbb-4563-a91b-60f5f4a26504"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Chart labels\n",
        "rating_count = rating_count[\"own_id\"].to_numpy()\n",
        "ratings = range(1, 6)\n",
        "\n",
        "# Show pie chart\n",
        "plt.title(\"Label Distribution\")\n",
        "plt.bar(x=ratings, height=rating_count)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUSIjmm6b0q"
      },
      "source": [
        "### Data Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DrKr_136b0t"
      },
      "source": [
        "##### Creating user profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "fMvj4hLx6b0t",
        "outputId": "ae5fe2ac-f2ae-48c4-f069-de405d5bb5a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>combined_rating</th>\n",
              "      <th>id</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 8</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1.000</td>\n",
              "      <td>12</td>\n",
              "      <td>0.882</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>0.764</td>\n",
              "      <td>13</td>\n",
              "      <td>0.781</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>0.764</td>\n",
              "      <td>14</td>\n",
              "      <td>0.843</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>0.756</td>\n",
              "      <td>15</td>\n",
              "      <td>0.719</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>0.828</td>\n",
              "      <td>16</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   own_id  inf_id  combined_rating  id  avg_rating  pricing_LOW  \\\n",
              "0       2      12            1.000  12       0.882            0   \n",
              "1       2      13            0.764  13       0.781            0   \n",
              "2       2      14            0.764  14       0.843            0   \n",
              "3       2      15            0.756  15       0.719            0   \n",
              "4       2      16            0.828  16       0.780            0   \n",
              "\n",
              "   pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  pricing_HIGH  ...  \\\n",
              "0                  0            1                  1             1  ...   \n",
              "1                  0            1                  1             1  ...   \n",
              "2                  0            1                  1             1  ...   \n",
              "3                  0            1                  0             0  ...   \n",
              "4                  0            1                  1             1  ...   \n",
              "\n",
              "   Category 8  Category 9  youtube_High  youtube_Low  youtube_Medium  \\\n",
              "0           0           0             1            0               0   \n",
              "1           0           0             1            0               0   \n",
              "2           0           0             1            0               0   \n",
              "3           1           1             1            0               0   \n",
              "4           1           0             1            0               0   \n",
              "\n",
              "   tiktok_High  tiktok_Low  tiktok_Medium  insta_follower_High  \\\n",
              "0            1           0              0                    1   \n",
              "1            1           0              0                    1   \n",
              "2            1           0              0                    1   \n",
              "3            1           0              0                    1   \n",
              "4            1           0              0                    1   \n",
              "\n",
              "   insta_follower_Medium  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 625,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_history = df_history.drop([\"star_rating\", \"sentiment_rating\"], axis=1)\n",
        "df_inf_features = pd.merge(df_history, df_inf_norm, left_on='inf_id', right_on='id', how='left')\n",
        "df_inf_features = df_inf_features.drop([\"star_rating\", \"sentiment_rating\"], axis=1)\n",
        "df_inf_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "6oYU-P1T6b0t",
        "outputId": "6be16577-592b-45e5-eec9-377e006ee8c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>Category 3</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 8</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.509590</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>0.057301</td>\n",
              "      <td>0.135744</td>\n",
              "      <td>0.623603</td>\n",
              "      <td>0.368666</td>\n",
              "      <td>0.286431</td>\n",
              "      <td>0.417197</td>\n",
              "      <td>0.001130</td>\n",
              "      <td>0.483450</td>\n",
              "      <td>0.076165</td>\n",
              "      <td>...</td>\n",
              "      <td>0.418162</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.595798</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232085</td>\n",
              "      <td>0.532061</td>\n",
              "      <td>0.001111</td>\n",
              "      <td>0.294711</td>\n",
              "      <td>0.632959</td>\n",
              "      <td>0.194925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>0.005261</td>\n",
              "      <td>0.014584</td>\n",
              "      <td>0.796327</td>\n",
              "      <td>0.584996</td>\n",
              "      <td>0.489712</td>\n",
              "      <td>0.478350</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>0.519346</td>\n",
              "      <td>0.033852</td>\n",
              "      <td>...</td>\n",
              "      <td>0.422272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.765743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064093</td>\n",
              "      <td>0.733650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.096187</td>\n",
              "      <td>0.799875</td>\n",
              "      <td>0.029961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>0.099986</td>\n",
              "      <td>0.646493</td>\n",
              "      <td>0.415127</td>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.413070</td>\n",
              "      <td>0.016141</td>\n",
              "      <td>0.467507</td>\n",
              "      <td>0.036324</td>\n",
              "      <td>...</td>\n",
              "      <td>0.328282</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.626141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.161972</td>\n",
              "      <td>0.571352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.216761</td>\n",
              "      <td>0.645507</td>\n",
              "      <td>0.142606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34</td>\n",
              "      <td>0.041405</td>\n",
              "      <td>0.107172</td>\n",
              "      <td>0.680172</td>\n",
              "      <td>0.392302</td>\n",
              "      <td>0.324397</td>\n",
              "      <td>0.426741</td>\n",
              "      <td>0.007138</td>\n",
              "      <td>0.449621</td>\n",
              "      <td>0.070328</td>\n",
              "      <td>...</td>\n",
              "      <td>0.444517</td>\n",
              "      <td>0.015112</td>\n",
              "      <td>0.650741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.187974</td>\n",
              "      <td>0.607810</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.230905</td>\n",
              "      <td>0.689664</td>\n",
              "      <td>0.149052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  pricing_LOW  pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  \\\n",
              "0   2     0.033024           0.071675     0.762157           0.509590   \n",
              "1  13     0.057301           0.135744     0.623603           0.368666   \n",
              "2  16     0.005261           0.014584     0.796327           0.584996   \n",
              "3  30     0.044451           0.099986     0.646493           0.415127   \n",
              "4  34     0.041405           0.107172     0.680172           0.392302   \n",
              "\n",
              "   pricing_HIGH  Category 1  Category 10  Category 2  Category 3  ...  \\\n",
              "0      0.433301    0.425542     0.001759    0.503988    0.113181  ...   \n",
              "1      0.286431    0.417197     0.001130    0.483450    0.076165  ...   \n",
              "2      0.489712    0.478350     0.004669    0.519346    0.033852  ...   \n",
              "3      0.336169    0.413070     0.016141    0.467507    0.036324  ...   \n",
              "4      0.324397    0.426741     0.007138    0.449621    0.070328  ...   \n",
              "\n",
              "   Category 8  Category 9  youtube_High  youtube_Low  youtube_Medium  \\\n",
              "0    0.430542    0.016373      0.751108          0.0        0.128289   \n",
              "1    0.418162    0.000000      0.595798          0.0        0.232085   \n",
              "2    0.422272    0.000000      0.765743          0.0        0.064093   \n",
              "3    0.328282    0.000000      0.626141          0.0        0.161972   \n",
              "4    0.444517    0.015112      0.650741          0.0        0.187974   \n",
              "\n",
              "   tiktok_High  tiktok_Low  tiktok_Medium  insta_follower_High  \\\n",
              "0     0.694771    0.000000       0.184627             0.757663   \n",
              "1     0.532061    0.001111       0.294711             0.632959   \n",
              "2     0.733650    0.000000       0.096187             0.799875   \n",
              "3     0.571352    0.000000       0.216761             0.645507   \n",
              "4     0.607810    0.000000       0.230905             0.689664   \n",
              "\n",
              "   insta_follower_Medium  \n",
              "0               0.121735  \n",
              "1               0.194925  \n",
              "2               0.029961  \n",
              "3               0.142606  \n",
              "4               0.149052  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 626,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "OWNER_FEATURES = df_inf_norm.columns[1:]\n",
        "\n",
        "# Copy influencer features combined with history data\n",
        "df_own_norm = df_inf_features.copy()\n",
        "\n",
        "# Multiply influencer feature with user rating\n",
        "df_own_norm[OWNER_FEATURES] = df_own_norm[OWNER_FEATURES].mul(df_own_norm['combined_rating'], axis=0) \n",
        "\n",
        "# Drop unimportant features\n",
        "df_own_norm = df_own_norm.drop([\"inf_id\", \"id\", \"combined_rating\"], axis=1)\n",
        "\n",
        "# Average those with same owner id to make user profile\n",
        "df_own_norm = df_own_norm.groupby('own_id').mean().reset_index()\n",
        "df_own_norm.rename(columns={'own_id': 'id'}, inplace=True)\n",
        "\n",
        "df_own_norm = df_own_norm.drop(['avg_rating'], axis=1)\n",
        "df_own_norm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74A492i96b0u"
      },
      "source": [
        "##### Process feature and label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdSaGqrr6b0u"
      },
      "source": [
        "Influencer features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "MbzVS77r6b0u",
        "outputId": "816b8c73-d73a-45be-c3ff-c487ab895983"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combined_rating</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 8</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.882</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.764</td>\n",
              "      <td>0.781</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.764</td>\n",
              "      <td>0.843</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.756</td>\n",
              "      <td>0.719</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.828</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   combined_rating  avg_rating  pricing_LOW  pricing_BELOW_AVG  pricing_AVG  \\\n",
              "0            1.000       0.882            0                  0            1   \n",
              "1            0.764       0.781            0                  0            1   \n",
              "2            0.764       0.843            0                  0            1   \n",
              "3            0.756       0.719            0                  0            1   \n",
              "4            0.828       0.780            0                  0            1   \n",
              "\n",
              "   pricing_ABOVE_AVG  pricing_HIGH  Category 1  Category 10  Category 2  ...  \\\n",
              "0                  1             1           1            0           1  ...   \n",
              "1                  1             1           1            0           0  ...   \n",
              "2                  1             1           1            0           1  ...   \n",
              "3                  0             0           1            0           1  ...   \n",
              "4                  1             1           1            0           1  ...   \n",
              "\n",
              "   Category 8  Category 9  youtube_High  youtube_Low  youtube_Medium  \\\n",
              "0           0           0             1            0               0   \n",
              "1           0           0             1            0               0   \n",
              "2           0           0             1            0               0   \n",
              "3           1           1             1            0               0   \n",
              "4           1           0             1            0               0   \n",
              "\n",
              "   tiktok_High  tiktok_Low  tiktok_Medium  insta_follower_High  \\\n",
              "0            1           0              0                    1   \n",
              "1            1           0              0                    1   \n",
              "2            1           0              0                    1   \n",
              "3            1           0              0                    1   \n",
              "4            1           0              0                    1   \n",
              "\n",
              "   insta_follower_Medium  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "execution_count": 627,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove ID and labels\n",
        "df_inf_features = df_inf_features.drop([\"own_id\", \"inf_id\", \"id\"], axis=1)\n",
        "\n",
        "df_inf_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMDk48Qd6b0u"
      },
      "outputs": [],
      "source": [
        "INFLUENCER_FEATURE_COUNT = len(df_inf_features.drop(\"combined_rating\", axis=1).columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D2Ov6e86b0u"
      },
      "source": [
        "Owner features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "-RNd1Gdp6b0u",
        "outputId": "dd22af83-67e0-4921-d07e-d26223084ecd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>combined_rating</th>\n",
              "      <th>id</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 8</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>0.764</td>\n",
              "      <td>2</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>0.764</td>\n",
              "      <td>2</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>0.756</td>\n",
              "      <td>2</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>0.828</td>\n",
              "      <td>2</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   own_id  inf_id  combined_rating  id  pricing_LOW  pricing_BELOW_AVG  \\\n",
              "0       2      12            1.000   2     0.033024           0.071675   \n",
              "1       2      13            0.764   2     0.033024           0.071675   \n",
              "2       2      14            0.764   2     0.033024           0.071675   \n",
              "3       2      15            0.756   2     0.033024           0.071675   \n",
              "4       2      16            0.828   2     0.033024           0.071675   \n",
              "\n",
              "   pricing_AVG  pricing_ABOVE_AVG  pricing_HIGH  Category 1  ...  Category 8  \\\n",
              "0     0.762157            0.50959      0.433301    0.425542  ...    0.430542   \n",
              "1     0.762157            0.50959      0.433301    0.425542  ...    0.430542   \n",
              "2     0.762157            0.50959      0.433301    0.425542  ...    0.430542   \n",
              "3     0.762157            0.50959      0.433301    0.425542  ...    0.430542   \n",
              "4     0.762157            0.50959      0.433301    0.425542  ...    0.430542   \n",
              "\n",
              "   Category 9  youtube_High  youtube_Low  youtube_Medium  tiktok_High  \\\n",
              "0    0.016373      0.751108          0.0        0.128289     0.694771   \n",
              "1    0.016373      0.751108          0.0        0.128289     0.694771   \n",
              "2    0.016373      0.751108          0.0        0.128289     0.694771   \n",
              "3    0.016373      0.751108          0.0        0.128289     0.694771   \n",
              "4    0.016373      0.751108          0.0        0.128289     0.694771   \n",
              "\n",
              "   tiktok_Low  tiktok_Medium  insta_follower_High  insta_follower_Medium  \n",
              "0         0.0       0.184627             0.757663               0.121735  \n",
              "1         0.0       0.184627             0.757663               0.121735  \n",
              "2         0.0       0.184627             0.757663               0.121735  \n",
              "3         0.0       0.184627             0.757663               0.121735  \n",
              "4         0.0       0.184627             0.757663               0.121735  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 629,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Join history and owner data by own_id\n",
        "df_own_features = pd.merge(df_history.drop([\"star_rating\", \"sentiment_rating\"], axis=1), df_own_norm, left_on='own_id', right_on='id', how='left')\n",
        "\n",
        "df_own_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "WKaAZyb46b0v",
        "outputId": "7ed54302-71ac-47ab-df82-fb773dcf6479"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combined_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>Category 3</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 8</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.764</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.764</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.756</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.828</td>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.50959</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   combined_rating  pricing_LOW  pricing_BELOW_AVG  pricing_AVG  \\\n",
              "0            1.000     0.033024           0.071675     0.762157   \n",
              "1            0.764     0.033024           0.071675     0.762157   \n",
              "2            0.764     0.033024           0.071675     0.762157   \n",
              "3            0.756     0.033024           0.071675     0.762157   \n",
              "4            0.828     0.033024           0.071675     0.762157   \n",
              "\n",
              "   pricing_ABOVE_AVG  pricing_HIGH  Category 1  Category 10  Category 2  \\\n",
              "0            0.50959      0.433301    0.425542     0.001759    0.503988   \n",
              "1            0.50959      0.433301    0.425542     0.001759    0.503988   \n",
              "2            0.50959      0.433301    0.425542     0.001759    0.503988   \n",
              "3            0.50959      0.433301    0.425542     0.001759    0.503988   \n",
              "4            0.50959      0.433301    0.425542     0.001759    0.503988   \n",
              "\n",
              "   Category 3  ...  Category 8  Category 9  youtube_High  youtube_Low  \\\n",
              "0    0.113181  ...    0.430542    0.016373      0.751108          0.0   \n",
              "1    0.113181  ...    0.430542    0.016373      0.751108          0.0   \n",
              "2    0.113181  ...    0.430542    0.016373      0.751108          0.0   \n",
              "3    0.113181  ...    0.430542    0.016373      0.751108          0.0   \n",
              "4    0.113181  ...    0.430542    0.016373      0.751108          0.0   \n",
              "\n",
              "   youtube_Medium  tiktok_High  tiktok_Low  tiktok_Medium  \\\n",
              "0        0.128289     0.694771         0.0       0.184627   \n",
              "1        0.128289     0.694771         0.0       0.184627   \n",
              "2        0.128289     0.694771         0.0       0.184627   \n",
              "3        0.128289     0.694771         0.0       0.184627   \n",
              "4        0.128289     0.694771         0.0       0.184627   \n",
              "\n",
              "   insta_follower_High  insta_follower_Medium  \n",
              "0             0.757663               0.121735  \n",
              "1             0.757663               0.121735  \n",
              "2             0.757663               0.121735  \n",
              "3             0.757663               0.121735  \n",
              "4             0.757663               0.121735  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 630,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove ID and labels\n",
        "df_own_features = df_own_features.drop([\"own_id\", \"inf_id\", \"id\"], axis=1)\n",
        "\n",
        "df_own_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E4olJ1L6b0v"
      },
      "outputs": [],
      "source": [
        "OWNER_FEATURE_COUNT = len(df_own_features.drop(\"combined_rating\", axis=1).columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-bFlBAN6b0v"
      },
      "source": [
        "Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvJFMFkt6b0v",
        "outputId": "aa6847cb-b646-4d1a-c251-408558ca10e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1.000\n",
              "1    0.764\n",
              "2    0.764\n",
              "3    0.756\n",
              "4    0.828\n",
              "Name: combined_rating, dtype: float64"
            ]
          },
          "execution_count": 632,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get labels from history data\n",
        "df_labels = df_history[\"combined_rating\"]\n",
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llgss9D-7Tiz"
      },
      "source": [
        "##### Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "qVuazy6w7C-r",
        "outputId": "ec747258-4367-4336-bb54-5a74c9435d03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>Category 3</th>\n",
              "      <th>Category 4</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 8</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.509590</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>0.444229</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.509590</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>0.444229</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.509590</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>0.444229</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.509590</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>0.444229</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.033024</td>\n",
              "      <td>0.071675</td>\n",
              "      <td>0.762157</td>\n",
              "      <td>0.509590</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.425542</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>0.113181</td>\n",
              "      <td>0.444229</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430542</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.751108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128289</td>\n",
              "      <td>0.694771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.121735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152888</th>\n",
              "      <td>0.163202</td>\n",
              "      <td>0.281885</td>\n",
              "      <td>0.506792</td>\n",
              "      <td>0.263843</td>\n",
              "      <td>0.220459</td>\n",
              "      <td>0.345921</td>\n",
              "      <td>0.004834</td>\n",
              "      <td>0.452822</td>\n",
              "      <td>0.073764</td>\n",
              "      <td>0.333076</td>\n",
              "      <td>...</td>\n",
              "      <td>0.335819</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.376822</td>\n",
              "      <td>0.404085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.450091</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>0.340556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152889</th>\n",
              "      <td>0.163202</td>\n",
              "      <td>0.281885</td>\n",
              "      <td>0.506792</td>\n",
              "      <td>0.263843</td>\n",
              "      <td>0.220459</td>\n",
              "      <td>0.345921</td>\n",
              "      <td>0.004834</td>\n",
              "      <td>0.452822</td>\n",
              "      <td>0.073764</td>\n",
              "      <td>0.333076</td>\n",
              "      <td>...</td>\n",
              "      <td>0.335819</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.376822</td>\n",
              "      <td>0.404085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.450091</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>0.340556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152890</th>\n",
              "      <td>0.163202</td>\n",
              "      <td>0.281885</td>\n",
              "      <td>0.506792</td>\n",
              "      <td>0.263843</td>\n",
              "      <td>0.220459</td>\n",
              "      <td>0.345921</td>\n",
              "      <td>0.004834</td>\n",
              "      <td>0.452822</td>\n",
              "      <td>0.073764</td>\n",
              "      <td>0.333076</td>\n",
              "      <td>...</td>\n",
              "      <td>0.335819</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.376822</td>\n",
              "      <td>0.404085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.450091</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>0.340556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152891</th>\n",
              "      <td>0.163202</td>\n",
              "      <td>0.281885</td>\n",
              "      <td>0.506792</td>\n",
              "      <td>0.263843</td>\n",
              "      <td>0.220459</td>\n",
              "      <td>0.345921</td>\n",
              "      <td>0.004834</td>\n",
              "      <td>0.452822</td>\n",
              "      <td>0.073764</td>\n",
              "      <td>0.333076</td>\n",
              "      <td>...</td>\n",
              "      <td>0.335819</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.376822</td>\n",
              "      <td>0.404085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.450091</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>0.340556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152892</th>\n",
              "      <td>0.163202</td>\n",
              "      <td>0.281885</td>\n",
              "      <td>0.506792</td>\n",
              "      <td>0.263843</td>\n",
              "      <td>0.220459</td>\n",
              "      <td>0.345921</td>\n",
              "      <td>0.004834</td>\n",
              "      <td>0.452822</td>\n",
              "      <td>0.073764</td>\n",
              "      <td>0.333076</td>\n",
              "      <td>...</td>\n",
              "      <td>0.335819</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.376822</td>\n",
              "      <td>0.404085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.450091</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>0.340556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152893 rows Ã— 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        pricing_LOW  pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  \\\n",
              "0          0.033024           0.071675     0.762157           0.509590   \n",
              "1          0.033024           0.071675     0.762157           0.509590   \n",
              "2          0.033024           0.071675     0.762157           0.509590   \n",
              "3          0.033024           0.071675     0.762157           0.509590   \n",
              "4          0.033024           0.071675     0.762157           0.509590   \n",
              "...             ...                ...          ...                ...   \n",
              "152888     0.163202           0.281885     0.506792           0.263843   \n",
              "152889     0.163202           0.281885     0.506792           0.263843   \n",
              "152890     0.163202           0.281885     0.506792           0.263843   \n",
              "152891     0.163202           0.281885     0.506792           0.263843   \n",
              "152892     0.163202           0.281885     0.506792           0.263843   \n",
              "\n",
              "        pricing_HIGH  Category 1  Category 10  Category 2  Category 3  \\\n",
              "0           0.433301    0.425542     0.001759    0.503988    0.113181   \n",
              "1           0.433301    0.425542     0.001759    0.503988    0.113181   \n",
              "2           0.433301    0.425542     0.001759    0.503988    0.113181   \n",
              "3           0.433301    0.425542     0.001759    0.503988    0.113181   \n",
              "4           0.433301    0.425542     0.001759    0.503988    0.113181   \n",
              "...              ...         ...          ...         ...         ...   \n",
              "152888      0.220459    0.345921     0.004834    0.452822    0.073764   \n",
              "152889      0.220459    0.345921     0.004834    0.452822    0.073764   \n",
              "152890      0.220459    0.345921     0.004834    0.452822    0.073764   \n",
              "152891      0.220459    0.345921     0.004834    0.452822    0.073764   \n",
              "152892      0.220459    0.345921     0.004834    0.452822    0.073764   \n",
              "\n",
              "        Category 4  ...  Category 8  Category 9  youtube_High  youtube_Low  \\\n",
              "0         0.444229  ...    0.430542    0.016373      0.751108          0.0   \n",
              "1         0.444229  ...    0.430542    0.016373      0.751108          0.0   \n",
              "2         0.444229  ...    0.430542    0.016373      0.751108          0.0   \n",
              "3         0.444229  ...    0.430542    0.016373      0.751108          0.0   \n",
              "4         0.444229  ...    0.430542    0.016373      0.751108          0.0   \n",
              "...            ...  ...         ...         ...           ...          ...   \n",
              "152888    0.333076  ...    0.335819    0.000000      0.477353          0.0   \n",
              "152889    0.333076  ...    0.335819    0.000000      0.477353          0.0   \n",
              "152890    0.333076  ...    0.335819    0.000000      0.477353          0.0   \n",
              "152891    0.333076  ...    0.335819    0.000000      0.477353          0.0   \n",
              "152892    0.333076  ...    0.335819    0.000000      0.477353          0.0   \n",
              "\n",
              "        youtube_Medium  tiktok_High  tiktok_Low  tiktok_Medium  \\\n",
              "0             0.128289     0.694771         0.0       0.184627   \n",
              "1             0.128289     0.694771         0.0       0.184627   \n",
              "2             0.128289     0.694771         0.0       0.184627   \n",
              "3             0.128289     0.694771         0.0       0.184627   \n",
              "4             0.128289     0.694771         0.0       0.184627   \n",
              "...                ...          ...         ...            ...   \n",
              "152888        0.376822     0.404085         0.0       0.450091   \n",
              "152889        0.376822     0.404085         0.0       0.450091   \n",
              "152890        0.376822     0.404085         0.0       0.450091   \n",
              "152891        0.376822     0.404085         0.0       0.450091   \n",
              "152892        0.376822     0.404085         0.0       0.450091   \n",
              "\n",
              "        insta_follower_High  insta_follower_Medium  \n",
              "0                  0.757663               0.121735  \n",
              "1                  0.757663               0.121735  \n",
              "2                  0.757663               0.121735  \n",
              "3                  0.757663               0.121735  \n",
              "4                  0.757663               0.121735  \n",
              "...                     ...                    ...  \n",
              "152888             0.513619               0.340556  \n",
              "152889             0.513619               0.340556  \n",
              "152890             0.513619               0.340556  \n",
              "152891             0.513619               0.340556  \n",
              "152892             0.513619               0.340556  \n",
              "\n",
              "[152893 rows x 23 columns]"
            ]
          },
          "execution_count": 633,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_inf_features = df_inf_features.drop([\"combined_rating\"], axis=1)\n",
        "df_own_features = df_own_features.drop([\"combined_rating\"], axis=1)\n",
        "df_own_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_own_features.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 634,
      "metadata": {
        "id": "PnmeND6m6fu8"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# Apply oversampling to each input type separately\n",
        "smote = SMOTE()\n",
        "df_features = pd.concat([df_inf_features, df_own_features], axis=1)\n",
        "# df_features, star_ratings = smote.fit_resample(df_features, df_history['star_rating'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 635,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rating_count = np.unique(star_ratings, return_counts=True) \n",
        "# rating_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 636,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Chart labels\n",
        "# rating_count = rating_count[1]\n",
        "# ratings = range(1, 6)\n",
        "\n",
        "# # Show pie chart\n",
        "# plt.title(\"Label Distribution\")\n",
        "# plt.bar(x=ratings, height=rating_count)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 637,
      "metadata": {},
      "outputs": [],
      "source": [
        "# star_ratings = star_ratings / 5\n",
        "# sentiment_ratings = star_ratings - 0.1 + 0.2 * random.random()\n",
        "# df_labels = pd.Series((STAR_WEIGHT * star_ratings + SENTIMENT_WEIGHT * sentiment_ratings).clip(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 638,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_data = pd.concat([df_features, df_labels], axis=1).sample(frac=1)\n",
        "df_data_pos = df_data[df_data[\"combined_rating\"] > 0.4]\n",
        "df_data_neg = df_data[df_data[\"combined_rating\"] <= 0.4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 639,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inf_features_pos = df_data_pos.iloc[:, :INFLUENCER_FEATURE_COUNT]\n",
        "df_own_features_pos = df_data_pos.iloc[:, INFLUENCER_FEATURE_COUNT:-1]\n",
        "df_labels_pos = df_data_pos.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 640,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inf_features_neg = df_data_neg.iloc[:, :INFLUENCER_FEATURE_COUNT]\n",
        "df_own_features_neg = df_data_neg.iloc[:, INFLUENCER_FEATURE_COUNT:-1]\n",
        "df_labels_neg = df_data_neg.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Generate train, validation, and test dataset (positive and negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 641,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive data: ({'inf_feature': TensorSpec(shape=(24,), dtype=tf.float64, name=None), 'own_feature': TensorSpec(shape=(23,), dtype=tf.float64, name=None)}, TensorSpec(shape=(), dtype=tf.float64, name=None))\n",
            "Count positive data: 148337\n",
            "\n",
            "Negative data: ({'inf_feature': TensorSpec(shape=(24,), dtype=tf.float64, name=None), 'own_feature': TensorSpec(shape=(23,), dtype=tf.float64, name=None)}, TensorSpec(shape=(), dtype=tf.float64, name=None))\n",
            "Count negative data: 4556\n"
          ]
        }
      ],
      "source": [
        "SHUFFLE_BUFFER = 1000\n",
        "\n",
        "dataset_pos = tf.data.Dataset.from_tensor_slices(({\"inf_feature\": df_inf_features_pos, \"own_feature\": df_own_features_pos}, df_labels_pos))\n",
        "dataset_pos = dataset_pos.shuffle(SHUFFLE_BUFFER) \n",
        "dataset_neg = tf.data.Dataset.from_tensor_slices(({\"inf_feature\": df_inf_features_neg, \"own_feature\": df_own_features_neg}, df_labels_neg))\n",
        "dataset_neg = dataset_neg.shuffle(SHUFFLE_BUFFER) \n",
        "\n",
        "print(\"Positive data:\", dataset_pos.element_spec)\n",
        "print(\"Count positive data:\", dataset_pos.cardinality().numpy())\n",
        "\n",
        "print(\"\\nNegative data:\", dataset_neg.element_spec)\n",
        "print(\"Count negative data:\", dataset_neg.cardinality().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 642,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive training dataset has 133503 data\n",
            "Positive validation dataset has 7416 data\n",
            "Positive testing dataset has 7418 data\n"
          ]
        }
      ],
      "source": [
        "# Generate training, validation, and testing data\n",
        "POSITIVE_SIZE = dataset_pos.cardinality().numpy()\n",
        "TRAIN_POS_SIZE = int(POSITIVE_SIZE * 0.9)\n",
        "VAL_POS_SIZE = int(POSITIVE_SIZE * 0.05)\n",
        "TEST_POS_SIZE = POSITIVE_SIZE - TRAIN_POS_SIZE - VAL_POS_SIZE\n",
        "\n",
        "train_dataset_pos = dataset_pos.take(TRAIN_POS_SIZE)\n",
        "val_dataset_pos = dataset_pos.skip(TRAIN_POS_SIZE).take(VAL_POS_SIZE)\n",
        "test_dataset_pos = dataset_pos.skip(TRAIN_POS_SIZE + VAL_POS_SIZE).take(TEST_POS_SIZE)\n",
        "\n",
        "print(f\"Positive training dataset has {train_dataset_pos.cardinality().numpy()} data\")\n",
        "print(f\"Positive validation dataset has {val_dataset_pos.cardinality().numpy()} data\")\n",
        "print(f\"Positive testing dataset has {test_dataset_pos.cardinality().numpy()} data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 643,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Negative training dataset has 2278 data\n",
            "Negative validation dataset has 1139 data\n",
            "Negative testing dataset has 1139 data\n"
          ]
        }
      ],
      "source": [
        "# Generate training, validation, and testing data\n",
        "NEGATIVE_SIZE = dataset_neg.cardinality().numpy()\n",
        "TRAIN_NEG_SIZE = int(NEGATIVE_SIZE * 0.5)\n",
        "VAL_NEG_SIZE = int(NEGATIVE_SIZE * 0.25)\n",
        "TEST_NEG_SIZE = NEGATIVE_SIZE - TRAIN_NEG_SIZE - VAL_NEG_SIZE\n",
        "\n",
        "train_dataset_neg = dataset_neg.take(TRAIN_NEG_SIZE)\n",
        "val_dataset_neg = dataset_neg.skip(TRAIN_NEG_SIZE).take(VAL_NEG_SIZE)\n",
        "test_dataset_neg = dataset_neg.skip(TRAIN_NEG_SIZE + VAL_NEG_SIZE).take(TEST_NEG_SIZE)\n",
        "\n",
        "print(f\"Negative training dataset has {train_dataset_neg.cardinality().numpy()} data\")\n",
        "print(f\"Negative validation dataset has {val_dataset_neg.cardinality().numpy()} data\")\n",
        "print(f\"Negative testing dataset has {test_dataset_neg.cardinality().numpy()} data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 644,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset has 135781 data\n",
            "Validation dataset has 8555 data\n",
            "Testing dataset has 8557 data\n"
          ]
        }
      ],
      "source": [
        "train_dataset = train_dataset_pos.concatenate(train_dataset_neg)\n",
        "val_dataset = val_dataset_pos.concatenate(val_dataset_neg)\n",
        "test_dataset = test_dataset_pos.concatenate(test_dataset_neg)\n",
        "\n",
        "print(f\"Training dataset has {train_dataset.cardinality().numpy()} data\")\n",
        "print(f\"Validation dataset has {val_dataset.cardinality().numpy()} data\")\n",
        "print(f\"Testing dataset has {test_dataset.cardinality().numpy()} data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 645,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batching\n",
        "REPEAT = 2\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Check Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 646,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_label(dataset):\n",
        "    labels = np.array([])\n",
        "    for batch in dataset:\n",
        "        labels = np.concatenate([labels, batch[1].numpy()])\n",
        "\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 647,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1, 2, 3, 4, 5, 6], dtype=int64),\n",
              " array([  521,  1656, 16443, 59600, 49815,  7746], dtype=int64))"
            ]
          },
          "execution_count": 647,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bin = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "bucket = np.digitize(get_label(train_dataset), bin)\n",
        "np.unique(bucket, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 648,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1, 2, 3, 4, 5, 6], dtype=int64),\n",
              " array([ 274,  804, 1003, 3367, 2698,  409], dtype=int64))"
            ]
          },
          "execution_count": 648,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bin = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "bucket = np.digitize(get_label(val_dataset), bin)\n",
        "np.unique(bucket, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 649,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1, 2, 3, 4, 5, 6], dtype=int64),\n",
              " array([ 258,  823,  984, 3289, 2760,  443], dtype=int64))"
            ]
          },
          "execution_count": 649,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bin = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "bucket = np.digitize(get_label(test_dataset), bin)\n",
        "np.unique(bucket, return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXSuhNrm6b0x"
      },
      "source": [
        "## Creating Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6kYNqE66b0x"
      },
      "source": [
        "Model consists of two neural networks that would be combined with Dot layer. The first neural network has influencer features as input and a vector as an output. The second one has owner features as input and a vector as an output. These two vectors will be combined with Dot layer and produces a single combined rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 650,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1rqEGj46b0x",
        "outputId": "e16af3bb-cd14-46ab-8760-0d52c3691dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inf_feature (InputLayer)       [(None, 24)]         0           []                               \n",
            "                                                                                                  \n",
            " own_feature (InputLayer)       [(None, 23)]         0           []                               \n",
            "                                                                                                  \n",
            " sequential_14 (Sequential)     (None, 32)           7328        ['inf_feature[0][0]']            \n",
            "                                                                                                  \n",
            " sequential_15 (Sequential)     (None, 32)           7200        ['own_feature[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_14 (TFOpL  (None, 32)          0           ['sequential_14[0][0]']          \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_15 (TFOpL  (None, 32)          0           ['sequential_15[0][0]']          \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " dot_7 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_14[0][0]',\n",
            "                                                                  'tf.math.l2_normalize_15[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,528\n",
            "Trainable params: 14,528\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "VECTOR_SIZE = 32\n",
        "# tf.random.set_seed(1)\n",
        "\n",
        "model_influencer = tf.keras.models.Sequential([\n",
        "    # tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.8),\n",
        "    # tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.9),\n",
        "    # tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.9),\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=VECTOR_SIZE, activation='linear'),\n",
        "])\n",
        "\n",
        "# create the influencer input and point to the base network\n",
        "input_influencer = tf.keras.layers.Input(shape=(INFLUENCER_FEATURE_COUNT), name=\"inf_feature\")\n",
        "vi = model_influencer(input_influencer)\n",
        "vi = tf.linalg.l2_normalize(vi, axis=1)\n",
        "\n",
        "model_owner = tf.keras.models.Sequential([\n",
        "    # tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.8),\n",
        "    # tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.9),\n",
        "    # tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.9),\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.9),\n",
        "    tf.keras.layers.Dense(units=VECTOR_SIZE, activation='linear'),\n",
        "])\n",
        "\n",
        "# create the owner input and point to the base network\n",
        "input_owner = tf.keras.layers.Input(shape=(OWNER_FEATURE_COUNT), name=\"own_feature\")\n",
        "vo = model_owner(input_owner)\n",
        "vo = tf.linalg.l2_normalize(vo, axis=1)\n",
        "\n",
        "# compute the dot product of the two vectors vi and vo\n",
        "output = tf.keras.layers.Dot(axes=1)([vi, vo])\n",
        "\n",
        "# specify the inputs and output of the model\n",
        "model = tf.keras.Model([input_influencer, input_owner], output)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 707,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtNfqm8D6b0y",
        "outputId": "54359439-1023-45cb-d362-4dacbf05e392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1061/1061 [==============================] - 3s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1351 - val_mse: 0.0362 - val_mae: 0.1351\n",
            "Epoch 2/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1342 - val_mse: 0.0357 - val_mae: 0.1342\n",
            "Epoch 3/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1344 - val_mse: 0.0359 - val_mae: 0.1344\n",
            "Epoch 4/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1005 - mse: 0.0173 - mae: 0.1005 - val_loss: 0.1345 - val_mse: 0.0357 - val_mae: 0.1345\n",
            "Epoch 5/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0173 - mae: 0.1004 - val_loss: 0.1350 - val_mse: 0.0359 - val_mae: 0.1350\n",
            "Epoch 6/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1005 - mse: 0.0173 - mae: 0.1005 - val_loss: 0.1345 - val_mse: 0.0357 - val_mae: 0.1345\n",
            "Epoch 7/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0173 - mae: 0.1004 - val_loss: 0.1349 - val_mse: 0.0362 - val_mae: 0.1349\n",
            "Epoch 8/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1005 - mse: 0.0173 - mae: 0.1005 - val_loss: 0.1352 - val_mse: 0.0361 - val_mae: 0.1352\n",
            "Epoch 9/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1344 - val_mse: 0.0359 - val_mae: 0.1344\n",
            "Epoch 10/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1350 - val_mse: 0.0359 - val_mae: 0.1350\n",
            "Epoch 11/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0173 - mae: 0.1004 - val_loss: 0.1347 - val_mse: 0.0358 - val_mae: 0.1347\n",
            "Epoch 12/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0173 - mae: 0.1004 - val_loss: 0.1349 - val_mse: 0.0361 - val_mae: 0.1349\n",
            "Epoch 13/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0173 - mae: 0.1004 - val_loss: 0.1345 - val_mse: 0.0357 - val_mae: 0.1345\n",
            "Epoch 14/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0172 - mae: 0.1004 - val_loss: 0.1353 - val_mse: 0.0363 - val_mae: 0.1353\n",
            "Epoch 15/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1346 - val_mse: 0.0360 - val_mae: 0.1346\n",
            "Epoch 16/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0173 - mae: 0.1004 - val_loss: 0.1346 - val_mse: 0.0357 - val_mae: 0.1346\n",
            "Epoch 17/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1340 - val_mse: 0.0354 - val_mae: 0.1340\n",
            "Epoch 18/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0173 - mae: 0.1004 - val_loss: 0.1345 - val_mse: 0.0359 - val_mae: 0.1345\n",
            "Epoch 19/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1345 - val_mse: 0.0357 - val_mae: 0.1345\n",
            "Epoch 20/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1338 - val_mse: 0.0352 - val_mae: 0.1338\n",
            "Epoch 21/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1348 - val_mse: 0.0360 - val_mae: 0.1348\n",
            "Epoch 22/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0172 - mae: 0.1003 - val_loss: 0.1344 - val_mse: 0.0359 - val_mae: 0.1344\n",
            "Epoch 23/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1344 - val_mse: 0.0357 - val_mae: 0.1344\n",
            "Epoch 24/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0172 - mae: 0.1003 - val_loss: 0.1344 - val_mse: 0.0355 - val_mae: 0.1344\n",
            "Epoch 25/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.0172 - mae: 0.1001 - val_loss: 0.1350 - val_mse: 0.0359 - val_mae: 0.1350\n",
            "Epoch 26/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0172 - mae: 0.1003 - val_loss: 0.1336 - val_mse: 0.0353 - val_mae: 0.1336\n",
            "Epoch 27/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0172 - mae: 0.1003 - val_loss: 0.1345 - val_mse: 0.0357 - val_mae: 0.1345\n",
            "Epoch 28/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0172 - mae: 0.1003 - val_loss: 0.1338 - val_mse: 0.0355 - val_mae: 0.1338\n",
            "Epoch 29/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1343 - val_mse: 0.0354 - val_mae: 0.1343\n",
            "Epoch 30/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0173 - mae: 0.1004 - val_loss: 0.1351 - val_mse: 0.0361 - val_mae: 0.1351\n",
            "Epoch 31/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.0172 - mae: 0.1004 - val_loss: 0.1338 - val_mse: 0.0352 - val_mae: 0.1338\n",
            "Epoch 32/300\n",
            "1061/1061 [==============================] - 2s 1ms/step - loss: 0.1003 - mse: 0.0172 - mae: 0.1003 - val_loss: 0.1342 - val_mse: 0.0354 - val_mae: 0.1342\n",
            "Epoch 33/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1345 - val_mse: 0.0358 - val_mae: 0.1345\n",
            "Epoch 34/300\n",
            "1061/1061 [==============================] - 2s 1ms/step - loss: 0.1003 - mse: 0.0172 - mae: 0.1003 - val_loss: 0.1345 - val_mse: 0.0359 - val_mae: 0.1345\n",
            "Epoch 35/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1337 - val_mse: 0.0355 - val_mae: 0.1337\n",
            "Epoch 36/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1340 - val_mse: 0.0357 - val_mae: 0.1340\n",
            "Epoch 37/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1351 - val_mse: 0.0359 - val_mae: 0.1351\n",
            "Epoch 38/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1347 - val_mse: 0.0359 - val_mae: 0.1347\n",
            "Epoch 39/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.0172 - mae: 0.1001 - val_loss: 0.1340 - val_mse: 0.0353 - val_mae: 0.1340\n",
            "Epoch 40/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1000 - mse: 0.0172 - mae: 0.1000 - val_loss: 0.1348 - val_mse: 0.0358 - val_mae: 0.1348\n",
            "Epoch 41/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.0172 - mae: 0.1001 - val_loss: 0.1346 - val_mse: 0.0359 - val_mae: 0.1346\n",
            "Epoch 42/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0173 - mae: 0.1003 - val_loss: 0.1340 - val_mse: 0.0353 - val_mae: 0.1340\n",
            "Epoch 43/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0172 - mae: 0.1003 - val_loss: 0.1336 - val_mse: 0.0350 - val_mae: 0.1336\n",
            "Epoch 44/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1348 - val_mse: 0.0360 - val_mae: 0.1348\n",
            "Epoch 45/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1342 - val_mse: 0.0355 - val_mae: 0.1342\n",
            "Epoch 46/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.0172 - mae: 0.1001 - val_loss: 0.1334 - val_mse: 0.0350 - val_mae: 0.1334\n",
            "Epoch 47/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1340 - val_mse: 0.0356 - val_mae: 0.1340\n",
            "Epoch 48/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.0172 - mae: 0.1001 - val_loss: 0.1339 - val_mse: 0.0355 - val_mae: 0.1339\n",
            "Epoch 49/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1345 - val_mse: 0.0357 - val_mae: 0.1345\n",
            "Epoch 50/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.0172 - mae: 0.1001 - val_loss: 0.1334 - val_mse: 0.0351 - val_mae: 0.1334\n",
            "Epoch 51/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1003 - mse: 0.0172 - mae: 0.1003 - val_loss: 0.1336 - val_mse: 0.0351 - val_mae: 0.1336\n",
            "Epoch 52/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1343 - val_mse: 0.0355 - val_mae: 0.1343\n",
            "Epoch 53/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.0172 - mae: 0.1001 - val_loss: 0.1343 - val_mse: 0.0353 - val_mae: 0.1343\n",
            "Epoch 54/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.0172 - mae: 0.1001 - val_loss: 0.1341 - val_mse: 0.0354 - val_mae: 0.1341\n",
            "Epoch 55/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.0172 - mae: 0.1002 - val_loss: 0.1336 - val_mse: 0.0352 - val_mae: 0.1336\n",
            "Epoch 56/300\n",
            "1061/1061 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.0172 - mae: 0.1001 - val_loss: 0.1342 - val_mse: 0.0361 - val_mae: 0.1342\n",
            "Epoch 57/300\n",
            "1008/1061 [===========================>..] - ETA: 0s - loss: 0.0949 - mse: 0.0144 - mae: 0.0949"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[707], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(KERAS_DIR, LOG_NAME))\n\u001b[0;32m     10\u001b[0m LOG_NAME \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataset, validation_data\u001b[39m=\u001b[39;49mval_dataset, epochs\u001b[39m=\u001b[39;49mEPOCH)\n\u001b[0;32m     12\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     13\u001b[0m training_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
            "File \u001b[1;32md:\\Apps2\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32md:\\Apps2\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32md:\\Apps2\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32md:\\Apps2\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32md:\\Apps2\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32md:\\Apps2\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32md:\\Apps2\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32md:\\Apps2\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32md:\\Apps2\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "model.compile(optimizer= OPTIMIZER, \n",
        "              loss=LOSS_FN,\n",
        "              metrics=[\"mse\", \"mae\"])\n",
        "\n",
        "# LOG_NAME = LOG_NAME[:-1]\n",
        "model = tf.keras.models.load_model(os.path.join(KERAS_DIR, LOG_NAME))\n",
        "LOG_NAME += \"I\"\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCH)\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_ppV-Ls6b0y"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, save=False):\n",
        "    # Extract the loss, MAE, and MSE values from the history object\n",
        "    loss = history.history['loss']\n",
        "    mse = history.history['mse']\n",
        "    mae = history.history['mae']\n",
        "    val_loss = history.history['val_loss']\n",
        "    val_mse = history.history['val_mse']\n",
        "    val_mae = history.history['val_mae']\n",
        "\n",
        "    # Create a figure and set up the subplots\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(9, 3))\n",
        "\n",
        "    # Plot the loss history\n",
        "    plt.title(REMARK)\n",
        "    ax1.plot(loss, label='Loss')\n",
        "    ax1.plot(val_loss, label='Val Loss')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    # Plot the MSE history\n",
        "    ax2.plot(mse, label='MSE')\n",
        "    ax2.plot(val_mse, label='Val MSE')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('MSE')\n",
        "    ax2.legend()\n",
        "\n",
        "    # Plot the MAE history\n",
        "    ax3.plot(mae, label='MAE')\n",
        "    ax3.plot(val_mae, label='Val MAE')\n",
        "    ax3.set_xlabel('Epochs')\n",
        "    ax3.set_ylabel('MAE')\n",
        "    ax3.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    if (save):\n",
        "        if (not os.path.exists(os.path.join(PLOT_DIR, LOG_NAME))):\n",
        "            plt.savefig(os.path.join(PLOT_DIR, LOG_NAME))\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "uZKCc_zA6b0y",
        "outputId": "000f1cc0-cca1-4775-ba9d-3dc5a821d2dc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x300 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_history(history, save=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcNEeSLn6b0y"
      },
      "source": [
        "### Evaluation with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSNAswWw6b0y",
        "outputId": "fcb7f48c-9ed5-45cb-d7fc-9f0a3a0bec87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67/67 [==============================] - 0s 970us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.87741065],\n",
              "       [0.81422114],\n",
              "       [0.77639896],\n",
              "       ...,\n",
              "       [0.6763321 ],\n",
              "       [0.8070545 ],\n",
              "       [0.7106554 ]], dtype=float32)"
            ]
          },
          "execution_count": 696,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_predict = model.predict(test_dataset)\n",
        "test_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3HTlJ9Sz6b0z",
        "outputId": "3bd26e97-daf0-4c94-a7da-4b41e912a528"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>real</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.877411</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.122589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.814221</td>\n",
              "      <td>0.960</td>\n",
              "      <td>0.145779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.776399</td>\n",
              "      <td>0.788</td>\n",
              "      <td>0.011601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.755059</td>\n",
              "      <td>0.752</td>\n",
              "      <td>0.003059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.834277</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.054277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8552</th>\n",
              "      <td>0.730047</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.598047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8553</th>\n",
              "      <td>0.723941</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.323941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8554</th>\n",
              "      <td>0.676332</td>\n",
              "      <td>0.348</td>\n",
              "      <td>0.328332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8555</th>\n",
              "      <td>0.807055</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.439055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8556</th>\n",
              "      <td>0.710655</td>\n",
              "      <td>0.384</td>\n",
              "      <td>0.326655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8557 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      predicted   real     error\n",
              "0      0.877411  1.000  0.122589\n",
              "1      0.814221  0.960  0.145779\n",
              "2      0.776399  0.788  0.011601\n",
              "3      0.755059  0.752  0.003059\n",
              "4      0.834277  0.780  0.054277\n",
              "...         ...    ...       ...\n",
              "8552   0.730047  0.132  0.598047\n",
              "8553   0.723941  0.400  0.323941\n",
              "8554   0.676332  0.348  0.328332\n",
              "8555   0.807055  0.368  0.439055\n",
              "8556   0.710655  0.384  0.326655\n",
              "\n",
              "[8557 rows x 3 columns]"
            ]
          },
          "execution_count": 697,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels = get_label(test_dataset)\n",
        "compare_test = pd.concat([pd.DataFrame(test_predict, columns=[\"predicted\"]), \n",
        "                     pd.DataFrame(test_labels, columns=[\"real\"])], axis=1)\n",
        "\n",
        "compare_test[\"error\"] = abs(compare_test[\"predicted\"] - compare_test[\"real\"])\n",
        "\n",
        "compare_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Aj27AgIK6b0z",
        "outputId": "512b6c4b-13c8-4e6c-c04b-be0be6b7870c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>real</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>0.911261</td>\n",
              "      <td>0.408</td>\n",
              "      <td>0.503261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5837</th>\n",
              "      <td>0.912507</td>\n",
              "      <td>0.412</td>\n",
              "      <td>0.500507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7426</th>\n",
              "      <td>0.748308</td>\n",
              "      <td>0.188</td>\n",
              "      <td>0.560308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7428</th>\n",
              "      <td>0.801572</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.617572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7431</th>\n",
              "      <td>0.758142</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.614142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8539</th>\n",
              "      <td>0.711510</td>\n",
              "      <td>0.140</td>\n",
              "      <td>0.571510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8541</th>\n",
              "      <td>0.730912</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.534912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8547</th>\n",
              "      <td>0.870634</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.550634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8549</th>\n",
              "      <td>0.741402</td>\n",
              "      <td>0.176</td>\n",
              "      <td>0.565402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8552</th>\n",
              "      <td>0.730047</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.598047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>297 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      predicted   real     error\n",
              "145    0.911261  0.408  0.503261\n",
              "5837   0.912507  0.412  0.500507\n",
              "7426   0.748308  0.188  0.560308\n",
              "7428   0.801572  0.184  0.617572\n",
              "7431   0.758142  0.144  0.614142\n",
              "...         ...    ...       ...\n",
              "8539   0.711510  0.140  0.571510\n",
              "8541   0.730912  0.196  0.534912\n",
              "8547   0.870634  0.320  0.550634\n",
              "8549   0.741402  0.176  0.565402\n",
              "8552   0.730047  0.132  0.598047\n",
              "\n",
              "[297 rows x 3 columns]"
            ]
          },
          "execution_count": 698,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare_test[compare_test[\"error\"] > 5e-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtZDYD7KInYN",
        "outputId": "fc8e8d93-1b34-42d4-f9b1-1385d9e4f660"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1547014156527172"
            ]
          },
          "execution_count": 699,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare_test[\"error\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAsiIuPT6b00"
      },
      "source": [
        "## Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuvKUV2I6b00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: log/model/savedmodel/recommender-small-simplerr-III\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: log/model/savedmodel/recommender-small-simplerr-III\\assets\n"
          ]
        }
      ],
      "source": [
        "if (not os.path.exists(os.path.join(MODEL_DIR, LOG_NAME))):\n",
        "    tf.saved_model.save(model, os.path.join(MODEL_DIR, LOG_NAME))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbR05q6a6b00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: log/model/keras/recommender-small-simplerr-III\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: log/model/keras/recommender-small-simplerr-III\\assets\n"
          ]
        }
      ],
      "source": [
        "if (not os.path.exists(os.path.join(KERAS_DIR, LOG_NAME))):\n",
        "    model.save(os.path.join(KERAS_DIR, LOG_NAME))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3icvT0z-6b00"
      },
      "outputs": [],
      "source": [
        "def serialize(obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        raise TypeError(\"Object of type {} is not JSON serializable\".format(type(obj)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS0MacWU6b00"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import timedelta\n",
        "\n",
        "log = {\n",
        "    \"name\": LOG_NAME,\n",
        "    \"training_time\": str(timedelta(training_time)),\n",
        "    \"remark\": REMARK,\n",
        "    \"test_error\": compare_test[\"error\"].mean(),\n",
        "    \"results\": {\n",
        "        \"last_loss\": history.history[\"loss\"][-1],\n",
        "        \"last_mae\": history.history[\"mae\"][-1],\n",
        "        \"last_mse\": history.history[\"mse\"][-1],\n",
        "        \"last_val_loss\": history.history[\"val_loss\"][-1],\n",
        "        \"last_val_mae\": history.history[\"val_mae\"][-1],\n",
        "        \"last_val_mse\": history.history[\"val_mse\"][-1],\n",
        "    },\n",
        "    \"hyperparameter\": {\n",
        "        \"learning_rate\": LEARNING_RATE,\n",
        "        \"epoch\": EPOCH,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"loss_func\": tf.keras.losses.serialize(LOSS_FN)[\"class_name\"],\n",
        "        \"optimizer\": tf.keras.optimizers.serialize(OPTIMIZER)[\"class_name\"],\n",
        "    },\n",
        "    # \"data_distribution\": {\n",
        "    #     \"positive\": POSITIVE_SIZE,\n",
        "    #     \"negative\": NEGATIVE_SIZE,\n",
        "    #     \"training_pos\": TRAIN_POS_SIZE,\n",
        "    #     \"training_neg\": TRAIN_NEG_SIZE,\n",
        "    # },\n",
        "    \"data_example\": {\n",
        "        \"influencer\": df_influencer.head().to_dict(),\n",
        "        \"owner\": df_own_norm.head().to_dict(),\n",
        "        \"history\": df_history.head().to_dict(),\n",
        "    },\n",
        "    \"eval\": {\n",
        "        \"loss\": history.history[\"loss\"],\n",
        "        \"mae\": history.history[\"mae\"],\n",
        "        \"mse\": history.history[\"mse\"],\n",
        "        \"val_loss\": history.history[\"val_loss\"],\n",
        "        \"val_mae\": history.history[\"val_mae\"],\n",
        "        \"val_mse\": history.history[\"val_mse\"],\n",
        "    }\n",
        "}\n",
        "if (not os.path.exists(os.path.join(DETAIL_DIR, LOG_NAME + \".json\"))):\n",
        "    with open(os.path.join(DETAIL_DIR, LOG_NAME + '.json'), 'w') as json_file:\n",
        "        log = json.dumps(log, default=serialize)\n",
        "        json_file.write(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuIJ-9tD6b00",
        "outputId": "46695dc1-cd73-4aa8-e8d4-b63b44853a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inf_feature (InputLayer)       [(None, 24)]         0           []                               \n",
            "                                                                                                  \n",
            " own_feature (InputLayer)       [(None, 23)]         0           []                               \n",
            "                                                                                                  \n",
            " sequential_14 (Sequential)     (None, 32)           7328        ['inf_feature[0][0]']            \n",
            "                                                                                                  \n",
            " sequential_15 (Sequential)     (None, 32)           7200        ['own_feature[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_14 (TFOpL  (None, 32)          0           ['sequential_14[0][0]']          \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_15 (TFOpL  (None, 32)          0           ['sequential_15[0][0]']          \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " dot_7 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_14[0][0]',\n",
            "                                                                  'tf.math.l2_normalize_15[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,528\n",
            "Trainable params: 14,528\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "summary = model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtEaCtRk6b00"
      },
      "outputs": [],
      "source": [
        "from contextlib import redirect_stdout\n",
        "\n",
        "with open(os.path.join(SUMMARY_DIR, LOG_NAME + \".txt\"), 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        print(\"Influencer Model:\")\n",
        "        model_influencer.summary()\n",
        "        \n",
        "        print(\"\\nOwner Model:\")\n",
        "        model_owner.summary()\n",
        "        \n",
        "        print(\"\\nFull Model:\")\n",
        "        model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Stopper' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[706], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Stopper\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Stopper' is not defined"
          ]
        }
      ],
      "source": [
        "Stopper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Generate train, validation, and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'inf_feature': TensorSpec(shape=(24,), dtype=tf.float64, name=None),\n",
              "  'own_feature': TensorSpec(shape=(23,), dtype=tf.float64, name=None)},\n",
              " TensorSpec(shape=(), dtype=tf.float64, name=None))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "SHUFFLE_BUFFER = 1000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(({\"inf_feature\": df_inf_features, \"own_feature\": df_own_features}, df_labels))\n",
        "dataset = dataset.shuffle(SHUFFLE_BUFFER) \n",
        "\n",
        "dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset has 377121 data\n",
            "Validation dataset has 9924 data\n",
            "Testing dataset has 9925 data\n"
          ]
        }
      ],
      "source": [
        "# Generate training, validation, and testing data\n",
        "DATASET_SIZE = dataset.cardinality().numpy()\n",
        "TRAIN_SIZE = int(DATASET_SIZE * 0.95)\n",
        "VAL_SIZE = int(DATASET_SIZE * 0.025)\n",
        "TEST_SIZE = DATASET_SIZE - TRAIN_SIZE - VAL_SIZE\n",
        "\n",
        "train_dataset = dataset.take(TRAIN_SIZE)\n",
        "val_dataset = dataset.skip(TRAIN_SIZE).take(VAL_SIZE)\n",
        "test_dataset = dataset.skip(TRAIN_SIZE + VAL_SIZE).take(TEST_SIZE)\n",
        "\n",
        "print(f\"Training dataset has {train_dataset.cardinality().numpy()} data\")\n",
        "print(f\"Validation dataset has {val_dataset.cardinality().numpy()} data\")\n",
        "print(f\"Testing dataset has {test_dataset.cardinality().numpy()} data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batching\n",
        "REPEAT = 2\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMvdAcM66b01"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4735e28f7f627569bc07f7dc41131ed5d08a93f3d94f12e74778d501b659619"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
