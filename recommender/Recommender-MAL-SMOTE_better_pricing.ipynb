{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0TIzX0K6b0i"
      },
      "source": [
        "# <center> Recommender System </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT9Y0Ah56b0k"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKd9UomS6b0k"
      },
      "source": [
        "Connect to drive (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltqyg7vA6b0k",
        "outputId": "f9d502cb-abd4-47a0-e7f5-4553dbbc4db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "DRIVE_DIR = \"\"\n",
        "USING_DRIVE = False\n",
        "if USING_DRIVE:\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    DRIVE_DIR = \"drive/My Drive/Bangkit/\"\n",
        "\n",
        "# Check GPU\n",
        "devices = tf.config.experimental.list_physical_devices()\n",
        "for device in devices:\n",
        "    print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "polD1-8m6b0l"
      },
      "source": [
        "Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "dHM-Im3g6b0l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "LOG_NAME = \"recommender-smote-simple\"\n",
        "REMARK = \"Try current best model with more relevant pricing\"\n",
        "BATCH_SIZE = 2024\n",
        "LEARNING_RATE = 1e-5\n",
        "EPOCH = 200\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "LOSS_FN = tf.keras.losses.MeanAbsoluteError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUCIib5V6b0m"
      },
      "source": [
        "Log dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stopper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "NgTRDLlo6b0m"
      },
      "outputs": [
        {
          "ename": "FileExistsError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[101], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m SUMMARY_DIR \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DRIVE_DIR, \u001b[39m\"\u001b[39m\u001b[39mlog/model/summary/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m (os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MODEL_DIR, LOG_NAME)) \u001b[39mor\u001b[39;00m \n\u001b[0;32m      8\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(KERAS_DIR, LOG_NAME)) \u001b[39mor\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(PLOT_DIR, LOG_NAME)) \u001b[39mor\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(SUMMARY_DIR, LOG_NAME)) \u001b[39mor\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DETAIL_DIR, LOG_NAME))):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m\n",
            "\u001b[1;31mFileExistsError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "DETAIL_DIR = os.path.join(DRIVE_DIR, \"log/detail/\")\n",
        "MODEL_DIR = os.path.join(DRIVE_DIR, \"log/model/savedmodel/\")\n",
        "KERAS_DIR = os.path.join(DRIVE_DIR, \"log/model/keras/\")\n",
        "PLOT_DIR = os.path.join(DRIVE_DIR, \"log/plot\")\n",
        "SUMMARY_DIR = os.path.join(DRIVE_DIR, \"log/model/summary/\")\n",
        "\n",
        "if (os.path.exists(os.path.join(MODEL_DIR, LOG_NAME)) or \n",
        "    os.path.exists(os.path.join(KERAS_DIR, LOG_NAME)) or\n",
        "    os.path.exists(os.path.join(PLOT_DIR, LOG_NAME)) or\n",
        "    os.path.exists(os.path.join(SUMMARY_DIR, LOG_NAME)) or\n",
        "    os.path.exists(os.path.join(DETAIL_DIR, LOG_NAME))):\n",
        "    raise FileExistsError\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUx0u7wS6b0m"
      },
      "source": [
        "## Data Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKdozaq36b0m"
      },
      "source": [
        "### Load data from CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adJLSdQH6b0n"
      },
      "source": [
        "Not using user data for a while"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWimNAkh6b0n"
      },
      "source": [
        "Data is generated randomly using Excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOY5h8C16b0n"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = os.path.join(DRIVE_DIR, \"data/synt_data_better_price_and_follower/\")\n",
        "INFLUENCER_FILE = os.path.join(DATA_DIR, \"data_content_influencer_categ.csv\")\n",
        "OWNER_FILE = os.path.join(DATA_DIR, \"data_content_owner_categ.csv\")\n",
        "HISTORY_FILE = os.path.join(DATA_DIR, \"historical_data.csv\")\n",
        "\n",
        "df_influencer = pd.read_csv(INFLUENCER_FILE)\n",
        "# df_owner = pd.read_csv(OWNER_FILE)\n",
        "df_history = pd.read_csv(HISTORY_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9FQwofA6b0n"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pRduYuFh6b0n",
        "outputId": "efa0a603-b46e-4beb-a15e-fcac12e66703"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>insta_follower</th>\n",
              "      <th>tiktok</th>\n",
              "      <th>youtube</th>\n",
              "      <th>categories</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>6018900</td>\n",
              "      <td>8078640</td>\n",
              "      <td>15046770</td>\n",
              "      <td>Category 8,Category 2</td>\n",
              "      <td>9.37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82</td>\n",
              "      <td>23809950</td>\n",
              "      <td>35177250</td>\n",
              "      <td>44279670</td>\n",
              "      <td>Category 4,Category 2,Category 1,Category 8,Ca...</td>\n",
              "      <td>9.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>296</td>\n",
              "      <td>3427860</td>\n",
              "      <td>5198670</td>\n",
              "      <td>5264340</td>\n",
              "      <td>Category 6,Category 1,Category 4,Category 5</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>127</td>\n",
              "      <td>20207160</td>\n",
              "      <td>38229630</td>\n",
              "      <td>74752350</td>\n",
              "      <td>Category 7,Category 6</td>\n",
              "      <td>9.17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137</td>\n",
              "      <td>4537980</td>\n",
              "      <td>8215080</td>\n",
              "      <td>13298910</td>\n",
              "      <td>Category 6,Category 1,Category 4,Category 5</td>\n",
              "      <td>9.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  insta_follower    tiktok   youtube  \\\n",
              "0  1723         6018900   8078640  15046770   \n",
              "1    82        23809950  35177250  44279670   \n",
              "2   296         3427860   5198670   5264340   \n",
              "3   127        20207160  38229630  74752350   \n",
              "4   137         4537980   8215080  13298910   \n",
              "\n",
              "                                          categories  avg_rating  pricing_LOW  \\\n",
              "0                              Category 8,Category 2        9.37            0   \n",
              "1  Category 4,Category 2,Category 1,Category 8,Ca...        9.26            0   \n",
              "2        Category 6,Category 1,Category 4,Category 5        9.25            0   \n",
              "3                              Category 7,Category 6        9.17            0   \n",
              "4        Category 6,Category 1,Category 4,Category 5        9.16            0   \n",
              "\n",
              "   pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  pricing_HIGH  \n",
              "0                  0            1                  1             1  \n",
              "1                  0            1                  1             1  \n",
              "2                  0            1                  1             0  \n",
              "3                  0            1                  1             1  \n",
              "4                  0            1                  1             1  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_influencer.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EgUvt646b0n",
        "outputId": "02a5b9c0-f6b9-4a29-edee-b43d0b15e10f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6406 entries, 0 to 6405\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 6406 non-null   int64  \n",
            " 1   insta_follower     6406 non-null   int64  \n",
            " 2   tiktok             6406 non-null   int64  \n",
            " 3   youtube            6406 non-null   int64  \n",
            " 4   categories         6406 non-null   object \n",
            " 5   avg_rating         6406 non-null   float64\n",
            " 6   pricing_LOW        6406 non-null   int64  \n",
            " 7   pricing_BELOW_AVG  6406 non-null   int64  \n",
            " 8   pricing_AVG        6406 non-null   int64  \n",
            " 9   pricing_ABOVE_AVG  6406 non-null   int64  \n",
            " 10  pricing_HIGH       6406 non-null   int64  \n",
            "dtypes: float64(1), int64(9), object(1)\n",
            "memory usage: 550.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df_influencer.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "t-gTa4GC6b0o",
        "outputId": "de289730-abaa-4205-c12b-ff2166c46796"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>insta_follower</th>\n",
              "      <th>tiktok</th>\n",
              "      <th>youtube</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6406.000000</td>\n",
              "      <td>6.406000e+03</td>\n",
              "      <td>6.406000e+03</td>\n",
              "      <td>6.406000e+03</td>\n",
              "      <td>6406.000000</td>\n",
              "      <td>6406.000000</td>\n",
              "      <td>6406.000000</td>\n",
              "      <td>6406.000000</td>\n",
              "      <td>6406.000000</td>\n",
              "      <td>6406.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3505.326881</td>\n",
              "      <td>9.936103e+05</td>\n",
              "      <td>1.405106e+06</td>\n",
              "      <td>1.952503e+06</td>\n",
              "      <td>6.954530</td>\n",
              "      <td>0.625976</td>\n",
              "      <td>0.716984</td>\n",
              "      <td>0.230097</td>\n",
              "      <td>0.089291</td>\n",
              "      <td>0.063534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2153.761090</td>\n",
              "      <td>2.158019e+06</td>\n",
              "      <td>3.200647e+06</td>\n",
              "      <td>4.601825e+06</td>\n",
              "      <td>0.804705</td>\n",
              "      <td>0.483908</td>\n",
              "      <td>0.450499</td>\n",
              "      <td>0.420927</td>\n",
              "      <td>0.285186</td>\n",
              "      <td>0.243940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.290000e+03</td>\n",
              "      <td>1.260000e+03</td>\n",
              "      <td>2.490000e+03</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1607.250000</td>\n",
              "      <td>6.016500e+04</td>\n",
              "      <td>8.160750e+04</td>\n",
              "      <td>1.084950e+05</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3312.500000</td>\n",
              "      <td>2.187150e+05</td>\n",
              "      <td>2.956500e+05</td>\n",
              "      <td>4.113000e+05</td>\n",
              "      <td>7.010000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5384.750000</td>\n",
              "      <td>8.947575e+05</td>\n",
              "      <td>1.201725e+06</td>\n",
              "      <td>1.692038e+06</td>\n",
              "      <td>7.470000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7387.000000</td>\n",
              "      <td>3.041751e+07</td>\n",
              "      <td>4.039176e+07</td>\n",
              "      <td>7.475235e+07</td>\n",
              "      <td>9.370000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id  insta_follower        tiktok       youtube   avg_rating  \\\n",
              "count  6406.000000    6.406000e+03  6.406000e+03  6.406000e+03  6406.000000   \n",
              "mean   3505.326881    9.936103e+05  1.405106e+06  1.952503e+06     6.954530   \n",
              "std    2153.761090    2.158019e+06  3.200647e+06  4.601825e+06     0.804705   \n",
              "min       1.000000    1.290000e+03  1.260000e+03  2.490000e+03     2.000000   \n",
              "25%    1607.250000    6.016500e+04  8.160750e+04  1.084950e+05     6.500000   \n",
              "50%    3312.500000    2.187150e+05  2.956500e+05  4.113000e+05     7.010000   \n",
              "75%    5384.750000    8.947575e+05  1.201725e+06  1.692038e+06     7.470000   \n",
              "max    7387.000000    3.041751e+07  4.039176e+07  7.475235e+07     9.370000   \n",
              "\n",
              "       pricing_LOW  pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  \\\n",
              "count  6406.000000        6406.000000  6406.000000        6406.000000   \n",
              "mean      0.625976           0.716984     0.230097           0.089291   \n",
              "std       0.483908           0.450499     0.420927           0.285186   \n",
              "min       0.000000           0.000000     0.000000           0.000000   \n",
              "25%       0.000000           0.000000     0.000000           0.000000   \n",
              "50%       1.000000           1.000000     0.000000           0.000000   \n",
              "75%       1.000000           1.000000     0.000000           0.000000   \n",
              "max       1.000000           1.000000     1.000000           1.000000   \n",
              "\n",
              "       pricing_HIGH  \n",
              "count   6406.000000  \n",
              "mean       0.063534  \n",
              "std        0.243940  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        0.000000  \n",
              "max        1.000000  "
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_influencer.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y5wNWPbA6b0o",
        "outputId": "4cefa513-c9b5-42c7-d5ad-b46838a373fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>sentiment_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   own_id  inf_id  star_rating  sentiment_rating\n",
              "0       1       1            4              0.77\n",
              "1       1       3            3              0.53\n",
              "2       1       5            5              0.89\n",
              "3       1       6            5              0.90\n",
              "4       1       7            4              0.80"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOa8c6Bx6b0o",
        "outputId": "04f2e6e9-6637-428c-b5f1-8bc09848c8bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 413446 entries, 0 to 413445\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   own_id            413446 non-null  int64  \n",
            " 1   inf_id            413446 non-null  int64  \n",
            " 2   star_rating       413446 non-null  int64  \n",
            " 3   sentiment_rating  413446 non-null  float64\n",
            "dtypes: float64(1), int64(3)\n",
            "memory usage: 12.6 MB\n"
          ]
        }
      ],
      "source": [
        "df_history.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "TBs_bu7J6b0o",
        "outputId": "2888c4cb-86a7-4e81-bade-ee1f375e1c79"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>sentiment_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>413446.000000</td>\n",
              "      <td>413446.000000</td>\n",
              "      <td>413446.000000</td>\n",
              "      <td>413446.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2443.219533</td>\n",
              "      <td>1076.748458</td>\n",
              "      <td>4.141170</td>\n",
              "      <td>0.777486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1438.596784</td>\n",
              "      <td>1148.850785</td>\n",
              "      <td>0.789503</td>\n",
              "      <td>0.161847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1214.000000</td>\n",
              "      <td>260.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2456.000000</td>\n",
              "      <td>639.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.790000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3699.000000</td>\n",
              "      <td>1532.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5000.000000</td>\n",
              "      <td>7385.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              own_id         inf_id    star_rating  sentiment_rating\n",
              "count  413446.000000  413446.000000  413446.000000     413446.000000\n",
              "mean     2443.219533    1076.748458       4.141170          0.777486\n",
              "std      1438.596784    1148.850785       0.789503          0.161847\n",
              "min         1.000000       1.000000       1.000000          0.000000\n",
              "25%      1214.000000     260.000000       4.000000          0.680000\n",
              "50%      2456.000000     639.000000       4.000000          0.790000\n",
              "75%      3699.000000    1532.000000       5.000000          0.900000\n",
              "max      5000.000000    7385.000000       5.000000          1.000000"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVn8QMc76b0o"
      },
      "source": [
        "## Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N30NlTAl6b0o"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rED6Pt5Z6b0o"
      },
      "source": [
        "#### Missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1XQOSWt6b0p",
        "outputId": "617ba75e-7c49-45b5-d531-4fe5f96010be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                   0\n",
              "insta_follower       0\n",
              "tiktok               0\n",
              "youtube              0\n",
              "categories           0\n",
              "avg_rating           0\n",
              "pricing_LOW          0\n",
              "pricing_BELOW_AVG    0\n",
              "pricing_AVG          0\n",
              "pricing_ABOVE_AVG    0\n",
              "pricing_HIGH         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_influencer.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MOCkxUR6b0p",
        "outputId": "9c983da4-5da7-4441-c403-dafa45460db3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "own_id              0\n",
              "inf_id              0\n",
              "star_rating         0\n",
              "sentiment_rating    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wLwW20o6b0p"
      },
      "source": [
        "No missing value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ2RmTtz6b0p"
      },
      "source": [
        "#### Irrelevant Data / Invalid Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS7foeoW6b0p"
      },
      "source": [
        "Check if all history has valid influencer and owner ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3I9fBI36b0p",
        "outputId": "3d0cddab-1eef-499a-9bb9-46099510f6d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history[\"inf_id\"].isin(df_influencer[\"id\"]).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us63TR4M6b0p"
      },
      "source": [
        "All history data has valid influencer and owner ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV8kcF2x6b0p"
      },
      "source": [
        "### Data Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyNya-nr6b0p"
      },
      "source": [
        "Normalize influencer data: Scale follower count and One-hot categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfHCwe6a6b0q"
      },
      "outputs": [],
      "source": [
        "def one_hot(df, column):\n",
        "    one_hot = df[column].str.get_dummies()\n",
        "    col_name = one_hot.columns\n",
        "    new_name = list(map(lambda name: column + \"_\" + name, col_name))\n",
        "    one_hot.rename(columns={k: v for k, v in zip(col_name, new_name)}, inplace=True)\n",
        "\n",
        "    df = pd.concat([df, one_hot], axis=1)\n",
        "    df = df.drop(column, axis=1)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "CpLHbZc_6b0q",
        "outputId": "597f0425-9cef-44f8-a974-b07251670b65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Low</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>0.937</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82</td>\n",
              "      <td>0.926</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>296</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>127</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  avg_rating  pricing_LOW  pricing_BELOW_AVG  pricing_AVG  \\\n",
              "0  1723       0.937            0                  0            1   \n",
              "1    82       0.926            0                  0            1   \n",
              "2   296       0.925            0                  0            1   \n",
              "3   127       0.917            0                  0            1   \n",
              "4   137       0.916            0                  0            1   \n",
              "\n",
              "   pricing_ABOVE_AVG  pricing_HIGH  Category 1  Category 10  Category 2  ...  \\\n",
              "0                  1             1           0            0           1  ...   \n",
              "1                  1             1           1            0           1  ...   \n",
              "2                  1             0           1            0           0  ...   \n",
              "3                  1             1           0            0           0  ...   \n",
              "4                  1             1           1            0           0  ...   \n",
              "\n",
              "   Category 9  youtube_High  youtube_Low  youtube_Medium  tiktok_High  \\\n",
              "0           0             1            0               0            1   \n",
              "1           0             1            0               0            1   \n",
              "2           0             1            0               0            1   \n",
              "3           0             1            0               0            1   \n",
              "4           0             1            0               0            1   \n",
              "\n",
              "   tiktok_Low  tiktok_Medium  insta_follower_High  insta_follower_Low  \\\n",
              "0           0              0                    1                   0   \n",
              "1           0              0                    1                   0   \n",
              "2           0              0                    1                   0   \n",
              "3           0              0                    1                   0   \n",
              "4           0              0                    1                   0   \n",
              "\n",
              "   insta_follower_Medium  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "YOUTUBE_HIGH_THRES = 2_000_000\n",
        "YOUTUBE_LOW_THRES = 100_000\n",
        "TIKTOK_HIGH_THRES = 2_000_000\n",
        "TIKTOK_LOW_THRES = 100_000\n",
        "INSTAGRAM_HIGH_THRES = 1_000_000\n",
        "INSTAGRAM_LOW_THRES = 50_000\n",
        "\n",
        "# follower_scaler = MinMaxScaler()\n",
        "\n",
        "df_inf_norm = df_influencer.copy()\n",
        "df_inf_norm['avg_rating'] = df_inf_norm[['avg_rating']] / 10\n",
        "# df_inf_norm[[\"insta_follower\", \"tiktok\", \"youtube\"]] = follower_scaler.fit_transform(df_inf_norm[[\"insta_follower\", \"tiktok\", \"youtube\"]])\n",
        "\n",
        "# df_inf_norm = one_hot(df_inf_norm, 'price_category') \n",
        "\n",
        "one_hot_categories = df_inf_norm['categories'].str.get_dummies(sep=',')\n",
        "df_inf_norm = pd.concat([df_inf_norm, one_hot_categories], axis=1)\n",
        "df_inf_norm = df_inf_norm.drop('categories', axis=1)\n",
        "\n",
        "youtube_bin = [0, YOUTUBE_LOW_THRES, YOUTUBE_HIGH_THRES, df_inf_norm['youtube'].max()]\n",
        "tiktok_bin = [0, TIKTOK_LOW_THRES, TIKTOK_HIGH_THRES, df_inf_norm['tiktok'].max()]\n",
        "insta_bin = [0, INSTAGRAM_LOW_THRES, INSTAGRAM_HIGH_THRES, df_inf_norm['insta_follower'].max()]\n",
        "\n",
        "df_inf_norm['youtube'] = pd.cut(df_inf_norm['youtube'],bins=youtube_bin, labels=[\"Low\", \"Medium\", \"High\"])  \n",
        "df_inf_norm = one_hot(df_inf_norm, 'youtube') \n",
        "\n",
        "df_inf_norm['tiktok'] = pd.cut(df_inf_norm['tiktok'],bins=tiktok_bin, labels=[\"Low\", \"Medium\", \"High\"])  \n",
        "df_inf_norm = one_hot(df_inf_norm, 'tiktok') \n",
        "\n",
        "df_inf_norm['insta_follower'] = pd.cut(df_inf_norm['insta_follower'],bins=insta_bin, labels=[\"Low\", \"Medium\", \"High\"])  \n",
        "df_inf_norm = one_hot(df_inf_norm, 'insta_follower') \n",
        "\n",
        "df_inf_norm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcb1BIyd6b0q"
      },
      "source": [
        "Combine star and sentiment rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DVaCP1n-6b0q",
        "outputId": "1c75bd32-5079-4ea1-94ac-efca455f8e71"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>sentiment_rating</th>\n",
              "      <th>combined_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413441</th>\n",
              "      <td>4999</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413442</th>\n",
              "      <td>4999</td>\n",
              "      <td>670</td>\n",
              "      <td>5</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413443</th>\n",
              "      <td>4999</td>\n",
              "      <td>62</td>\n",
              "      <td>5</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413444</th>\n",
              "      <td>4999</td>\n",
              "      <td>770</td>\n",
              "      <td>5</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413445</th>\n",
              "      <td>5000</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.985</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>413446 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        own_id  inf_id  star_rating  sentiment_rating  combined_rating\n",
              "0            1       1            4              0.77            0.785\n",
              "1            1       3            3              0.53            0.565\n",
              "2            1       5            5              0.89            0.945\n",
              "3            1       6            5              0.90            0.950\n",
              "4            1       7            4              0.80            0.800\n",
              "...        ...     ...          ...               ...              ...\n",
              "413441    4999      49            5              0.90            0.950\n",
              "413442    4999     670            5              0.84            0.920\n",
              "413443    4999      62            5              0.92            0.960\n",
              "413444    4999     770            5              0.93            0.965\n",
              "413445    5000      19            5              0.97            0.985\n",
              "\n",
              "[413446 rows x 5 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "STAR_WEIGHT = 0.5\n",
        "SENTIMENT_WEIGHT = 0.5\n",
        "\n",
        "df_history[\"combined_rating\"] = STAR_WEIGHT * df_history[\"star_rating\"] / 5 + SENTIMENT_WEIGHT * df_history[\"sentiment_rating\"]\n",
        "df_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "B-Q_KqeL6b0q",
        "outputId": "c2f11855-ee72-4abd-abae-a0d9ba95defd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>sentiment_rating</th>\n",
              "      <th>combined_rating</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>star_rating</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2768</td>\n",
              "      <td>2768</td>\n",
              "      <td>2768</td>\n",
              "      <td>2768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9217</td>\n",
              "      <td>9217</td>\n",
              "      <td>9217</td>\n",
              "      <td>9217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59531</td>\n",
              "      <td>59531</td>\n",
              "      <td>59531</td>\n",
              "      <td>59531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>197295</td>\n",
              "      <td>197295</td>\n",
              "      <td>197295</td>\n",
              "      <td>197295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>144635</td>\n",
              "      <td>144635</td>\n",
              "      <td>144635</td>\n",
              "      <td>144635</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             own_id  inf_id  sentiment_rating  combined_rating\n",
              "star_rating                                                   \n",
              "1              2768    2768              2768             2768\n",
              "2              9217    9217              9217             9217\n",
              "3             59531   59531             59531            59531\n",
              "4            197295  197295            197295           197295\n",
              "5            144635  144635            144635           144635"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rating_count = df_history.groupby(\"star_rating\").count()\n",
        "rating_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "HC9K0tAC6b0q",
        "outputId": "468ee171-bfbb-4563-a91b-60f5f4a26504"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Chart labels\n",
        "rating_count = rating_count[\"own_id\"].to_numpy()\n",
        "ratings = range(1, 6)\n",
        "\n",
        "# Show pie chart\n",
        "plt.title(\"Label Distribution\")\n",
        "plt.bar(x=ratings, height=rating_count)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUSIjmm6b0q"
      },
      "source": [
        "### Data Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DrKr_136b0t"
      },
      "source": [
        "##### Creating user profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "fMvj4hLx6b0t",
        "outputId": "ae5fe2ac-f2ae-48c4-f069-de405d5bb5a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>combined_rating</th>\n",
              "      <th>id</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Low</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.785</td>\n",
              "      <td>1</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.565</td>\n",
              "      <td>3</td>\n",
              "      <td>0.685</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.945</td>\n",
              "      <td>5</td>\n",
              "      <td>0.754</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.950</td>\n",
              "      <td>6</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.800</td>\n",
              "      <td>7</td>\n",
              "      <td>0.830</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   own_id  inf_id  combined_rating  id  avg_rating  pricing_LOW  \\\n",
              "0       1       1            0.785   1       0.735            0   \n",
              "1       1       3            0.565   3       0.685            0   \n",
              "2       1       5            0.945   5       0.754            0   \n",
              "3       1       6            0.950   6       0.871            0   \n",
              "4       1       7            0.800   7       0.830            0   \n",
              "\n",
              "   pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  pricing_HIGH  ...  \\\n",
              "0                  0            1                  1             1  ...   \n",
              "1                  0            1                  0             0  ...   \n",
              "2                  0            1                  0             0  ...   \n",
              "3                  0            1                  1             1  ...   \n",
              "4                  0            1                  1             1  ...   \n",
              "\n",
              "   Category 9  youtube_High  youtube_Low  youtube_Medium  tiktok_High  \\\n",
              "0           0             1            0               0            1   \n",
              "1           0             1            0               0            1   \n",
              "2           0             1            0               0            1   \n",
              "3           0             1            0               0            1   \n",
              "4           0             1            0               0            1   \n",
              "\n",
              "   tiktok_Low  tiktok_Medium  insta_follower_High  insta_follower_Low  \\\n",
              "0           0              0                    1                   0   \n",
              "1           0              0                    1                   0   \n",
              "2           0              0                    1                   0   \n",
              "3           0              0                    1                   0   \n",
              "4           0              0                    1                   0   \n",
              "\n",
              "   insta_follower_Medium  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_history = df_history.drop([\"star_rating\", \"sentiment_rating\"], axis=1)\n",
        "df_inf_features = pd.merge(df_history, df_inf_norm, left_on='inf_id', right_on='id', how='left')\n",
        "df_inf_features = df_inf_features.drop([\"star_rating\", \"sentiment_rating\"], axis=1)\n",
        "df_inf_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "6oYU-P1T6b0t",
        "outputId": "6be16577-592b-45e5-eec9-377e006ee8c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>Category 3</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Low</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.821250</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.821250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.821250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.821250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.036617</td>\n",
              "      <td>0.07491</td>\n",
              "      <td>0.753428</td>\n",
              "      <td>0.503832</td>\n",
              "      <td>0.428503</td>\n",
              "      <td>0.422844</td>\n",
              "      <td>0.001737</td>\n",
              "      <td>0.500150</td>\n",
              "      <td>0.114371</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017784</td>\n",
              "      <td>0.742545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.131033</td>\n",
              "      <td>0.686916</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.186662</td>\n",
              "      <td>0.749042</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.828676</td>\n",
              "      <td>0.615441</td>\n",
              "      <td>0.560294</td>\n",
              "      <td>0.381029</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.476618</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.793088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.088824</td>\n",
              "      <td>0.776029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.105882</td>\n",
              "      <td>0.881912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.825732</td>\n",
              "      <td>0.772927</td>\n",
              "      <td>0.713902</td>\n",
              "      <td>0.684268</td>\n",
              "      <td>0.019146</td>\n",
              "      <td>0.412439</td>\n",
              "      <td>0.038049</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.825732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.807439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018293</td>\n",
              "      <td>0.825732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.01736</td>\n",
              "      <td>0.782079</td>\n",
              "      <td>0.651404</td>\n",
              "      <td>0.541629</td>\n",
              "      <td>0.288876</td>\n",
              "      <td>0.006910</td>\n",
              "      <td>0.501236</td>\n",
              "      <td>0.168371</td>\n",
              "      <td>...</td>\n",
              "      <td>0.051292</td>\n",
              "      <td>0.767303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045225</td>\n",
              "      <td>0.767303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045225</td>\n",
              "      <td>0.795169</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  pricing_LOW  pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  \\\n",
              "0   1     0.000000            0.00000     0.821250           0.632500   \n",
              "1   2     0.036617            0.07491     0.753428           0.503832   \n",
              "2   3     0.000000            0.00000     0.828676           0.615441   \n",
              "3   4     0.000000            0.00000     0.825732           0.772927   \n",
              "4   5     0.000000            0.01736     0.782079           0.651404   \n",
              "\n",
              "   pricing_HIGH  Category 1  Category 10  Category 2  Category 3  ...  \\\n",
              "0      0.632500    0.296875     0.000000    0.631875    0.000000  ...   \n",
              "1      0.428503    0.422844     0.001737    0.500150    0.114371  ...   \n",
              "2      0.560294    0.381029     0.000000    0.476618    0.000000  ...   \n",
              "3      0.713902    0.684268     0.019146    0.412439    0.038049  ...   \n",
              "4      0.541629    0.288876     0.006910    0.501236    0.168371  ...   \n",
              "\n",
              "   Category 9  youtube_High  youtube_Low  youtube_Medium  tiktok_High  \\\n",
              "0    0.000000      0.821250          0.0        0.000000     0.821250   \n",
              "1    0.017784      0.742545          0.0        0.131033     0.686916   \n",
              "2    0.000000      0.793088          0.0        0.088824     0.776029   \n",
              "3    0.000000      0.825732          0.0        0.000000     0.807439   \n",
              "4    0.051292      0.767303          0.0        0.045225     0.767303   \n",
              "\n",
              "   tiktok_Low  tiktok_Medium  insta_follower_High  insta_follower_Low  \\\n",
              "0         0.0       0.000000             0.821250                 0.0   \n",
              "1         0.0       0.186662             0.749042                 0.0   \n",
              "2         0.0       0.105882             0.881912                 0.0   \n",
              "3         0.0       0.018293             0.825732                 0.0   \n",
              "4         0.0       0.045225             0.795169                 0.0   \n",
              "\n",
              "   insta_follower_Medium  \n",
              "0               0.000000  \n",
              "1               0.124536  \n",
              "2               0.000000  \n",
              "3               0.000000  \n",
              "4               0.017360  \n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "OWNER_FEATURES = df_inf_norm.columns[1:]\n",
        "\n",
        "# Copy influencer features combined with history data\n",
        "df_own_norm = df_inf_features.copy()\n",
        "\n",
        "# Multiply influencer feature with user rating\n",
        "df_own_norm[OWNER_FEATURES] = df_own_norm[OWNER_FEATURES].mul(df_own_norm['combined_rating'], axis=0) \n",
        "\n",
        "# Drop unimportant features\n",
        "df_own_norm = df_own_norm.drop([\"inf_id\", \"id\", \"combined_rating\"], axis=1)\n",
        "\n",
        "# Average those with same owner id to make user profile\n",
        "df_own_norm = df_own_norm.groupby('own_id').mean().reset_index()\n",
        "df_own_norm.rename(columns={'own_id': 'id'}, inplace=True)\n",
        "\n",
        "df_own_norm = df_own_norm.drop(['avg_rating'], axis=1)\n",
        "df_own_norm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74A492i96b0u"
      },
      "source": [
        "##### Process feature and label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdSaGqrr6b0u"
      },
      "source": [
        "Influencer features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "MbzVS77r6b0u",
        "outputId": "816b8c73-d73a-45be-c3ff-c487ab895983"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combined_rating</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Low</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.785</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.565</td>\n",
              "      <td>0.685</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.945</td>\n",
              "      <td>0.754</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.950</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.800</td>\n",
              "      <td>0.830</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   combined_rating  avg_rating  pricing_LOW  pricing_BELOW_AVG  pricing_AVG  \\\n",
              "0            0.785       0.735            0                  0            1   \n",
              "1            0.565       0.685            0                  0            1   \n",
              "2            0.945       0.754            0                  0            1   \n",
              "3            0.950       0.871            0                  0            1   \n",
              "4            0.800       0.830            0                  0            1   \n",
              "\n",
              "   pricing_ABOVE_AVG  pricing_HIGH  Category 1  Category 10  Category 2  ...  \\\n",
              "0                  1             1           1            0           1  ...   \n",
              "1                  0             0           0            0           0  ...   \n",
              "2                  0             0           0            0           1  ...   \n",
              "3                  1             1           0            0           0  ...   \n",
              "4                  1             1           0            0           1  ...   \n",
              "\n",
              "   Category 9  youtube_High  youtube_Low  youtube_Medium  tiktok_High  \\\n",
              "0           0             1            0               0            1   \n",
              "1           0             1            0               0            1   \n",
              "2           0             1            0               0            1   \n",
              "3           0             1            0               0            1   \n",
              "4           0             1            0               0            1   \n",
              "\n",
              "   tiktok_Low  tiktok_Medium  insta_follower_High  insta_follower_Low  \\\n",
              "0           0              0                    1                   0   \n",
              "1           0              0                    1                   0   \n",
              "2           0              0                    1                   0   \n",
              "3           0              0                    1                   0   \n",
              "4           0              0                    1                   0   \n",
              "\n",
              "   insta_follower_Medium  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove ID and labels\n",
        "df_inf_features = df_inf_features.drop([\"own_id\", \"inf_id\", \"id\"], axis=1)\n",
        "\n",
        "df_inf_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMDk48Qd6b0u"
      },
      "outputs": [],
      "source": [
        "INFLUENCER_FEATURE_COUNT = len(df_inf_features.drop(\"combined_rating\", axis=1).columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D2Ov6e86b0u"
      },
      "source": [
        "Owner features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "-RNd1Gdp6b0u",
        "outputId": "dd22af83-67e0-4921-d07e-d26223084ecd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>own_id</th>\n",
              "      <th>inf_id</th>\n",
              "      <th>combined_rating</th>\n",
              "      <th>id</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Low</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.785</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.565</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.945</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.950</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.800</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   own_id  inf_id  combined_rating  id  pricing_LOW  pricing_BELOW_AVG  \\\n",
              "0       1       1            0.785   1          0.0                0.0   \n",
              "1       1       3            0.565   1          0.0                0.0   \n",
              "2       1       5            0.945   1          0.0                0.0   \n",
              "3       1       6            0.950   1          0.0                0.0   \n",
              "4       1       7            0.800   1          0.0                0.0   \n",
              "\n",
              "   pricing_AVG  pricing_ABOVE_AVG  pricing_HIGH  Category 1  ...  Category 9  \\\n",
              "0      0.82125             0.6325        0.6325    0.296875  ...         0.0   \n",
              "1      0.82125             0.6325        0.6325    0.296875  ...         0.0   \n",
              "2      0.82125             0.6325        0.6325    0.296875  ...         0.0   \n",
              "3      0.82125             0.6325        0.6325    0.296875  ...         0.0   \n",
              "4      0.82125             0.6325        0.6325    0.296875  ...         0.0   \n",
              "\n",
              "   youtube_High  youtube_Low  youtube_Medium  tiktok_High  tiktok_Low  \\\n",
              "0       0.82125          0.0             0.0      0.82125         0.0   \n",
              "1       0.82125          0.0             0.0      0.82125         0.0   \n",
              "2       0.82125          0.0             0.0      0.82125         0.0   \n",
              "3       0.82125          0.0             0.0      0.82125         0.0   \n",
              "4       0.82125          0.0             0.0      0.82125         0.0   \n",
              "\n",
              "   tiktok_Medium  insta_follower_High  insta_follower_Low  \\\n",
              "0            0.0              0.82125                 0.0   \n",
              "1            0.0              0.82125                 0.0   \n",
              "2            0.0              0.82125                 0.0   \n",
              "3            0.0              0.82125                 0.0   \n",
              "4            0.0              0.82125                 0.0   \n",
              "\n",
              "   insta_follower_Medium  \n",
              "0                    0.0  \n",
              "1                    0.0  \n",
              "2                    0.0  \n",
              "3                    0.0  \n",
              "4                    0.0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Join history and owner data by own_id\n",
        "df_own_features = pd.merge(df_history.drop([\"star_rating\", \"sentiment_rating\"], axis=1), df_own_norm, left_on='own_id', right_on='id', how='left')\n",
        "\n",
        "df_own_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "WKaAZyb46b0v",
        "outputId": "7ed54302-71ac-47ab-df82-fb773dcf6479"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combined_rating</th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>Category 3</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Low</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.785</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.565</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.945</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.950</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.800</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   combined_rating  pricing_LOW  pricing_BELOW_AVG  pricing_AVG  \\\n",
              "0            0.785          0.0                0.0      0.82125   \n",
              "1            0.565          0.0                0.0      0.82125   \n",
              "2            0.945          0.0                0.0      0.82125   \n",
              "3            0.950          0.0                0.0      0.82125   \n",
              "4            0.800          0.0                0.0      0.82125   \n",
              "\n",
              "   pricing_ABOVE_AVG  pricing_HIGH  Category 1  Category 10  Category 2  \\\n",
              "0             0.6325        0.6325    0.296875          0.0    0.631875   \n",
              "1             0.6325        0.6325    0.296875          0.0    0.631875   \n",
              "2             0.6325        0.6325    0.296875          0.0    0.631875   \n",
              "3             0.6325        0.6325    0.296875          0.0    0.631875   \n",
              "4             0.6325        0.6325    0.296875          0.0    0.631875   \n",
              "\n",
              "   Category 3  ...  Category 9  youtube_High  youtube_Low  youtube_Medium  \\\n",
              "0         0.0  ...         0.0       0.82125          0.0             0.0   \n",
              "1         0.0  ...         0.0       0.82125          0.0             0.0   \n",
              "2         0.0  ...         0.0       0.82125          0.0             0.0   \n",
              "3         0.0  ...         0.0       0.82125          0.0             0.0   \n",
              "4         0.0  ...         0.0       0.82125          0.0             0.0   \n",
              "\n",
              "   tiktok_High  tiktok_Low  tiktok_Medium  insta_follower_High  \\\n",
              "0      0.82125         0.0            0.0              0.82125   \n",
              "1      0.82125         0.0            0.0              0.82125   \n",
              "2      0.82125         0.0            0.0              0.82125   \n",
              "3      0.82125         0.0            0.0              0.82125   \n",
              "4      0.82125         0.0            0.0              0.82125   \n",
              "\n",
              "   insta_follower_Low  insta_follower_Medium  \n",
              "0                 0.0                    0.0  \n",
              "1                 0.0                    0.0  \n",
              "2                 0.0                    0.0  \n",
              "3                 0.0                    0.0  \n",
              "4                 0.0                    0.0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove ID and labels\n",
        "df_own_features = df_own_features.drop([\"own_id\", \"inf_id\", \"id\"], axis=1)\n",
        "\n",
        "df_own_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E4olJ1L6b0v"
      },
      "outputs": [],
      "source": [
        "OWNER_FEATURE_COUNT = len(df_own_features.drop(\"combined_rating\", axis=1).columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-bFlBAN6b0v"
      },
      "source": [
        "Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvJFMFkt6b0v",
        "outputId": "aa6847cb-b646-4d1a-c251-408558ca10e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.785\n",
              "1    0.565\n",
              "2    0.945\n",
              "3    0.950\n",
              "4    0.800\n",
              "Name: combined_rating, dtype: float64"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get labels from history data\n",
        "df_labels = df_history[\"combined_rating\"]\n",
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llgss9D-7Tiz"
      },
      "source": [
        "##### Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "qVuazy6w7C-r",
        "outputId": "ec747258-4367-4336-bb54-5a74c9435d03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pricing_LOW</th>\n",
              "      <th>pricing_BELOW_AVG</th>\n",
              "      <th>pricing_AVG</th>\n",
              "      <th>pricing_ABOVE_AVG</th>\n",
              "      <th>pricing_HIGH</th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 10</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>Category 3</th>\n",
              "      <th>Category 4</th>\n",
              "      <th>...</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>youtube_High</th>\n",
              "      <th>youtube_Low</th>\n",
              "      <th>youtube_Medium</th>\n",
              "      <th>tiktok_High</th>\n",
              "      <th>tiktok_Low</th>\n",
              "      <th>tiktok_Medium</th>\n",
              "      <th>insta_follower_High</th>\n",
              "      <th>insta_follower_Low</th>\n",
              "      <th>insta_follower_Medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.63250</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.82125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413441</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.948750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413442</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.948750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413443</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.948750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413444</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.948750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413445</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.98500</td>\n",
              "      <td>0.98500</td>\n",
              "      <td>0.98500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.985000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.98500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.98500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.98500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.98500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>413446 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        pricing_LOW  pricing_BELOW_AVG  pricing_AVG  pricing_ABOVE_AVG  \\\n",
              "0               0.0                0.0      0.82125            0.63250   \n",
              "1               0.0                0.0      0.82125            0.63250   \n",
              "2               0.0                0.0      0.82125            0.63250   \n",
              "3               0.0                0.0      0.82125            0.63250   \n",
              "4               0.0                0.0      0.82125            0.63250   \n",
              "...             ...                ...          ...                ...   \n",
              "413441          0.0                0.0      0.94875            0.94875   \n",
              "413442          0.0                0.0      0.94875            0.94875   \n",
              "413443          0.0                0.0      0.94875            0.94875   \n",
              "413444          0.0                0.0      0.94875            0.94875   \n",
              "413445          0.0                0.0      0.98500            0.98500   \n",
              "\n",
              "        pricing_HIGH  Category 1  Category 10  Category 2  Category 3  \\\n",
              "0            0.63250    0.296875          0.0    0.631875         0.0   \n",
              "1            0.63250    0.296875          0.0    0.631875         0.0   \n",
              "2            0.63250    0.296875          0.0    0.631875         0.0   \n",
              "3            0.63250    0.296875          0.0    0.631875         0.0   \n",
              "4            0.63250    0.296875          0.0    0.631875         0.0   \n",
              "...              ...         ...          ...         ...         ...   \n",
              "413441       0.94875    0.948750          0.0    0.477500         0.0   \n",
              "413442       0.94875    0.948750          0.0    0.477500         0.0   \n",
              "413443       0.94875    0.948750          0.0    0.477500         0.0   \n",
              "413444       0.94875    0.948750          0.0    0.477500         0.0   \n",
              "413445       0.98500    0.000000          0.0    0.985000         0.0   \n",
              "\n",
              "        Category 4  ...  Category 9  youtube_High  youtube_Low  \\\n",
              "0          0.00000  ...         0.0       0.82125          0.0   \n",
              "1          0.00000  ...         0.0       0.82125          0.0   \n",
              "2          0.00000  ...         0.0       0.82125          0.0   \n",
              "3          0.00000  ...         0.0       0.82125          0.0   \n",
              "4          0.00000  ...         0.0       0.82125          0.0   \n",
              "...            ...  ...         ...           ...          ...   \n",
              "413441     0.94875  ...         0.0       0.94875          0.0   \n",
              "413442     0.94875  ...         0.0       0.94875          0.0   \n",
              "413443     0.94875  ...         0.0       0.94875          0.0   \n",
              "413444     0.94875  ...         0.0       0.94875          0.0   \n",
              "413445     0.98500  ...         0.0       0.98500          0.0   \n",
              "\n",
              "        youtube_Medium  tiktok_High  tiktok_Low  tiktok_Medium  \\\n",
              "0                  0.0      0.82125         0.0            0.0   \n",
              "1                  0.0      0.82125         0.0            0.0   \n",
              "2                  0.0      0.82125         0.0            0.0   \n",
              "3                  0.0      0.82125         0.0            0.0   \n",
              "4                  0.0      0.82125         0.0            0.0   \n",
              "...                ...          ...         ...            ...   \n",
              "413441             0.0      0.94875         0.0            0.0   \n",
              "413442             0.0      0.94875         0.0            0.0   \n",
              "413443             0.0      0.94875         0.0            0.0   \n",
              "413444             0.0      0.94875         0.0            0.0   \n",
              "413445             0.0      0.98500         0.0            0.0   \n",
              "\n",
              "        insta_follower_High  insta_follower_Low  insta_follower_Medium  \n",
              "0                   0.82125                 0.0                    0.0  \n",
              "1                   0.82125                 0.0                    0.0  \n",
              "2                   0.82125                 0.0                    0.0  \n",
              "3                   0.82125                 0.0                    0.0  \n",
              "4                   0.82125                 0.0                    0.0  \n",
              "...                     ...                 ...                    ...  \n",
              "413441              0.94875                 0.0                    0.0  \n",
              "413442              0.94875                 0.0                    0.0  \n",
              "413443              0.94875                 0.0                    0.0  \n",
              "413444              0.94875                 0.0                    0.0  \n",
              "413445              0.98500                 0.0                    0.0  \n",
              "\n",
              "[413446 rows x 24 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_inf_features = df_inf_features.drop([\"combined_rating\"], axis=1)\n",
        "df_own_features = df_own_features.drop([\"combined_rating\"], axis=1)\n",
        "df_own_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnmeND6m6fu8"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# Apply oversampling to each input type separately\n",
        "smote = SMOTE()\n",
        "df_features = pd.concat([df_inf_features, df_own_features], axis=1)\n",
        "df_features, star_ratings = smote.fit_resample(df_features, df_history['star_rating'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1, 2, 3, 4, 5], dtype=int64),\n",
              " array([197295, 197295, 197295, 197295, 197295], dtype=int64))"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rating_count = np.unique(star_ratings, return_counts=True) \n",
        "rating_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Chart labels\n",
        "rating_count = rating_count[1]\n",
        "ratings = range(1, 6)\n",
        "\n",
        "# Show pie chart\n",
        "plt.title(\"Label Distribution\")\n",
        "plt.bar(x=ratings, height=rating_count)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "star_ratings = star_ratings / 5\n",
        "sentiment_ratings = star_ratings - 0.1 + 0.2 * random.random()\n",
        "df_labels = pd.Series((STAR_WEIGHT * star_ratings + SENTIMENT_WEIGHT * sentiment_ratings).clip(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_data = pd.concat([df_features, df_labels], axis=1).sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inf_features = df_data.iloc[:, :INFLUENCER_FEATURE_COUNT]\n",
        "df_own_features = df_data.iloc[:, INFLUENCER_FEATURE_COUNT:-1]\n",
        "df_labels = df_data.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDz_rWfW6b0w"
      },
      "source": [
        "##### Generate train, validation, and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mBFlXc86b0w",
        "outputId": "72776d62-0e59-4bac-d667-6f7f3787c316"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'inf_feature': TensorSpec(shape=(25,), dtype=tf.float64, name=None),\n",
              "  'own_feature': TensorSpec(shape=(24,), dtype=tf.float64, name=None)},\n",
              " TensorSpec(shape=(), dtype=tf.float64, name=None))"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SHUFFLE_BUFFER = 1000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(({\"inf_feature\": df_inf_features, \"own_feature\": df_own_features}, df_labels))\n",
        "dataset = dataset.shuffle(SHUFFLE_BUFFER) \n",
        "\n",
        "dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE0vHoVu6b0w",
        "outputId": "39234da8-ef3a-489a-b162-2d218ad91508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset has 937151 data\n",
            "Validation dataset has 24661 data\n",
            "Testing dataset has 24663 data\n"
          ]
        }
      ],
      "source": [
        "# Generate training, validation, and testing data\n",
        "DATASET_SIZE = dataset.cardinality().numpy()\n",
        "TRAIN_SIZE = int(DATASET_SIZE * 0.95)\n",
        "VAL_SIZE = int(DATASET_SIZE * 0.025)\n",
        "TEST_SIZE = DATASET_SIZE - TRAIN_SIZE - VAL_SIZE\n",
        "\n",
        "train_dataset = dataset.take(TRAIN_SIZE)\n",
        "val_dataset = dataset.skip(TRAIN_SIZE).take(VAL_SIZE)\n",
        "test_dataset = dataset.skip(TRAIN_SIZE + VAL_SIZE).take(TEST_SIZE)\n",
        "\n",
        "print(f\"Training dataset has {train_dataset.cardinality().numpy()} data\")\n",
        "print(f\"Validation dataset has {val_dataset.cardinality().numpy()} data\")\n",
        "print(f\"Testing dataset has {test_dataset.cardinality().numpy()} data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_wOylH_6b0w"
      },
      "outputs": [],
      "source": [
        "# Batching\n",
        "REPEAT = 2\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Check Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_label(dataset):\n",
        "    labels = np.array([])\n",
        "    for batch in dataset:\n",
        "        labels = np.concatenate([labels, batch[1].numpy()])\n",
        "\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2, 3, 4, 5, 6], dtype=int64),\n",
              " array([187481, 187356, 187383, 187384, 187547], dtype=int64))"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bin = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "bucket = np.digitize(get_label(train_dataset), bin)\n",
        "np.unique(bucket, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2, 3, 4, 5, 6], dtype=int64),\n",
              " array([4876, 4968, 4983, 5000, 4834], dtype=int64))"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bin = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "bucket = np.digitize(get_label(val_dataset), bin)\n",
        "np.unique(bucket, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2, 3, 4, 5, 6], dtype=int64),\n",
              " array([4943, 4974, 4904, 4927, 4915], dtype=int64))"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bin = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "bucket = np.digitize(get_label(test_dataset), bin)\n",
        "np.unique(bucket, return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXSuhNrm6b0x"
      },
      "source": [
        "## Creating Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6kYNqE66b0x"
      },
      "source": [
        "Model consists of two neural networks that would be combined with Dot layer. The first neural network has influencer features as input and a vector as an output. The second one has owner features as input and a vector as an output. These two vectors will be combined with Dot layer and produces a single combined rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1rqEGj46b0x",
        "outputId": "e16af3bb-cd14-46ab-8760-0d52c3691dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inf_feature (InputLayer)       [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " own_feature (InputLayer)       [(None, 24)]         0           []                               \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 64)           23104       ['inf_feature[0][0]']            \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)      (None, 64)           22848       ['own_feature[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_2 (TFOpLa  (None, 64)          0           ['sequential_2[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_3 (TFOpLa  (None, 64)          0           ['sequential_3[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_2[0][0]', \n",
            "                                                                  'tf.math.l2_normalize_3[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 45,952\n",
            "Trainable params: 45,952\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "VECTOR_SIZE = 64\n",
        "# tf.random.set_seed(1)\n",
        "\n",
        "model_influencer = tf.keras.models.Sequential([\n",
        "    # tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.9),\n",
        "    # tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.9),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.9),\n",
        "    # tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=VECTOR_SIZE, activation='linear'),\n",
        "])\n",
        "\n",
        "# create the influencer input and point to the base network\n",
        "input_influencer = tf.keras.layers.Input(shape=(INFLUENCER_FEATURE_COUNT), name=\"inf_feature\")\n",
        "vi = model_influencer(input_influencer)\n",
        "vi = tf.linalg.l2_normalize(vi, axis=1)\n",
        "\n",
        "model_owner = tf.keras.models.Sequential([\n",
        "    # tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.9),\n",
        "    # tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.9),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.9),\n",
        "    # tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=VECTOR_SIZE, activation='linear'),\n",
        "])\n",
        "\n",
        "# create the owner input and point to the base network\n",
        "input_owner = tf.keras.layers.Input(shape=(OWNER_FEATURE_COUNT), name=\"own_feature\")\n",
        "vo = model_owner(input_owner)\n",
        "vo = tf.linalg.l2_normalize(vo, axis=1)\n",
        "\n",
        "# compute the dot product of the two vectors vi and vo\n",
        "output = tf.keras.layers.Dot(axes=1)([vi, vo])\n",
        "\n",
        "# specify the inputs and output of the model\n",
        "model = tf.keras.Model([input_influencer, input_owner], output)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtNfqm8D6b0y",
        "outputId": "54359439-1023-45cb-d362-4dacbf05e392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "464/464 [==============================] - 13s 16ms/step - loss: 0.5677 - mse: 0.4116 - mae: 0.5677 - val_loss: 0.2539 - val_mse: 0.0908 - val_mae: 0.2539\n",
            "Epoch 2/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.4406 - mse: 0.2726 - mae: 0.4406 - val_loss: 0.3138 - val_mse: 0.1510 - val_mae: 0.3138\n",
            "Epoch 3/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.3396 - mse: 0.1705 - mae: 0.3396 - val_loss: 0.3400 - val_mse: 0.1765 - val_mae: 0.3400\n",
            "Epoch 4/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2875 - mse: 0.1194 - mae: 0.2875 - val_loss: 0.3487 - val_mse: 0.1861 - val_mae: 0.3487\n",
            "Epoch 5/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2636 - mse: 0.0967 - mae: 0.2636 - val_loss: 0.3537 - val_mse: 0.1915 - val_mae: 0.3537\n",
            "Epoch 6/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2523 - mse: 0.0866 - mae: 0.2523 - val_loss: 0.3557 - val_mse: 0.1940 - val_mae: 0.3557\n",
            "Epoch 7/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2468 - mse: 0.0820 - mae: 0.2468 - val_loss: 0.3565 - val_mse: 0.1947 - val_mae: 0.3565\n",
            "Epoch 8/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.2437 - mse: 0.0797 - mae: 0.2437 - val_loss: 0.3555 - val_mse: 0.1939 - val_mae: 0.3555\n",
            "Epoch 9/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2417 - mse: 0.0784 - mae: 0.2417 - val_loss: 0.3529 - val_mse: 0.1910 - val_mae: 0.3529\n",
            "Epoch 10/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2404 - mse: 0.0776 - mae: 0.2404 - val_loss: 0.3499 - val_mse: 0.1879 - val_mae: 0.3499\n",
            "Epoch 11/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2391 - mse: 0.0769 - mae: 0.2391 - val_loss: 0.3444 - val_mse: 0.1825 - val_mae: 0.3444\n",
            "Epoch 12/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2378 - mse: 0.0761 - mae: 0.2378 - val_loss: 0.3391 - val_mse: 0.1770 - val_mae: 0.3391\n",
            "Epoch 13/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2367 - mse: 0.0755 - mae: 0.2367 - val_loss: 0.3331 - val_mse: 0.1711 - val_mae: 0.3331\n",
            "Epoch 14/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2354 - mse: 0.0748 - mae: 0.2354 - val_loss: 0.3262 - val_mse: 0.1644 - val_mae: 0.3262\n",
            "Epoch 15/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2342 - mse: 0.0740 - mae: 0.2342 - val_loss: 0.3196 - val_mse: 0.1579 - val_mae: 0.3196\n",
            "Epoch 16/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.2328 - mse: 0.0732 - mae: 0.2328 - val_loss: 0.3111 - val_mse: 0.1501 - val_mae: 0.3111\n",
            "Epoch 17/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.2311 - mse: 0.0721 - mae: 0.2311 - val_loss: 0.3034 - val_mse: 0.1427 - val_mae: 0.3034\n",
            "Epoch 18/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.2292 - mse: 0.0710 - mae: 0.2292 - val_loss: 0.2947 - val_mse: 0.1347 - val_mae: 0.2947\n",
            "Epoch 19/200\n",
            "464/464 [==============================] - 9s 18ms/step - loss: 0.2267 - mse: 0.0696 - mae: 0.2267 - val_loss: 0.2859 - val_mse: 0.1269 - val_mae: 0.2859\n",
            "Epoch 20/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.2235 - mse: 0.0680 - mae: 0.2235 - val_loss: 0.2759 - val_mse: 0.1184 - val_mae: 0.2759\n",
            "Epoch 21/200\n",
            "464/464 [==============================] - 9s 19ms/step - loss: 0.2195 - mse: 0.0660 - mae: 0.2195 - val_loss: 0.2656 - val_mse: 0.1102 - val_mae: 0.2656\n",
            "Epoch 22/200\n",
            "464/464 [==============================] - 9s 19ms/step - loss: 0.2145 - mse: 0.0638 - mae: 0.2145 - val_loss: 0.2546 - val_mse: 0.1023 - val_mae: 0.2546\n",
            "Epoch 23/200\n",
            "464/464 [==============================] - 9s 18ms/step - loss: 0.2094 - mse: 0.0616 - mae: 0.2094 - val_loss: 0.2445 - val_mse: 0.0957 - val_mae: 0.2445\n",
            "Epoch 24/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.2045 - mse: 0.0597 - mae: 0.2045 - val_loss: 0.2356 - val_mse: 0.0903 - val_mae: 0.2356\n",
            "Epoch 25/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.2002 - mse: 0.0581 - mae: 0.2002 - val_loss: 0.2271 - val_mse: 0.0851 - val_mae: 0.2271\n",
            "Epoch 26/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1968 - mse: 0.0569 - mae: 0.1968 - val_loss: 0.2193 - val_mse: 0.0805 - val_mae: 0.2193\n",
            "Epoch 27/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1938 - mse: 0.0558 - mae: 0.1938 - val_loss: 0.2122 - val_mse: 0.0762 - val_mae: 0.2122\n",
            "Epoch 28/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1913 - mse: 0.0549 - mae: 0.1913 - val_loss: 0.2060 - val_mse: 0.0725 - val_mae: 0.2060\n",
            "Epoch 29/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1887 - mse: 0.0540 - mae: 0.1887 - val_loss: 0.2010 - val_mse: 0.0697 - val_mae: 0.2010\n",
            "Epoch 30/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1869 - mse: 0.0534 - mae: 0.1869 - val_loss: 0.1964 - val_mse: 0.0668 - val_mae: 0.1964\n",
            "Epoch 31/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1853 - mse: 0.0528 - mae: 0.1853 - val_loss: 0.1937 - val_mse: 0.0652 - val_mae: 0.1937\n",
            "Epoch 32/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1837 - mse: 0.0522 - mae: 0.1837 - val_loss: 0.1901 - val_mse: 0.0631 - val_mae: 0.1901\n",
            "Epoch 33/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1824 - mse: 0.0517 - mae: 0.1824 - val_loss: 0.1881 - val_mse: 0.0620 - val_mae: 0.1881\n",
            "Epoch 34/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1813 - mse: 0.0513 - mae: 0.1813 - val_loss: 0.1854 - val_mse: 0.0605 - val_mae: 0.1854\n",
            "Epoch 35/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1800 - mse: 0.0508 - mae: 0.1800 - val_loss: 0.1840 - val_mse: 0.0596 - val_mae: 0.1840\n",
            "Epoch 36/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1792 - mse: 0.0505 - mae: 0.1792 - val_loss: 0.1816 - val_mse: 0.0583 - val_mae: 0.1816\n",
            "Epoch 37/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1783 - mse: 0.0502 - mae: 0.1783 - val_loss: 0.1807 - val_mse: 0.0578 - val_mae: 0.1807\n",
            "Epoch 38/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1776 - mse: 0.0499 - mae: 0.1776 - val_loss: 0.1785 - val_mse: 0.0564 - val_mae: 0.1785\n",
            "Epoch 39/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1769 - mse: 0.0497 - mae: 0.1769 - val_loss: 0.1774 - val_mse: 0.0558 - val_mae: 0.1774\n",
            "Epoch 40/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1762 - mse: 0.0494 - mae: 0.1762 - val_loss: 0.1761 - val_mse: 0.0551 - val_mae: 0.1761\n",
            "Epoch 41/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1756 - mse: 0.0491 - mae: 0.1756 - val_loss: 0.1754 - val_mse: 0.0547 - val_mae: 0.1754\n",
            "Epoch 42/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1748 - mse: 0.0488 - mae: 0.1748 - val_loss: 0.1745 - val_mse: 0.0542 - val_mae: 0.1745\n",
            "Epoch 43/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1743 - mse: 0.0486 - mae: 0.1743 - val_loss: 0.1731 - val_mse: 0.0533 - val_mae: 0.1731\n",
            "Epoch 44/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1738 - mse: 0.0484 - mae: 0.1738 - val_loss: 0.1730 - val_mse: 0.0534 - val_mae: 0.1730\n",
            "Epoch 45/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1734 - mse: 0.0482 - mae: 0.1734 - val_loss: 0.1717 - val_mse: 0.0526 - val_mae: 0.1717\n",
            "Epoch 46/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1727 - mse: 0.0479 - mae: 0.1727 - val_loss: 0.1705 - val_mse: 0.0520 - val_mae: 0.1705\n",
            "Epoch 47/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1723 - mse: 0.0478 - mae: 0.1723 - val_loss: 0.1700 - val_mse: 0.0516 - val_mae: 0.1700\n",
            "Epoch 48/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1719 - mse: 0.0476 - mae: 0.1719 - val_loss: 0.1692 - val_mse: 0.0513 - val_mae: 0.1692\n",
            "Epoch 49/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1715 - mse: 0.0475 - mae: 0.1715 - val_loss: 0.1688 - val_mse: 0.0510 - val_mae: 0.1688\n",
            "Epoch 50/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.1711 - mse: 0.0473 - mae: 0.1711 - val_loss: 0.1685 - val_mse: 0.0508 - val_mae: 0.1685\n",
            "Epoch 51/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1708 - mse: 0.0472 - mae: 0.1708 - val_loss: 0.1682 - val_mse: 0.0506 - val_mae: 0.1682\n",
            "Epoch 52/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1704 - mse: 0.0471 - mae: 0.1704 - val_loss: 0.1674 - val_mse: 0.0501 - val_mae: 0.1674\n",
            "Epoch 53/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1701 - mse: 0.0469 - mae: 0.1701 - val_loss: 0.1670 - val_mse: 0.0500 - val_mae: 0.1670\n",
            "Epoch 54/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1698 - mse: 0.0468 - mae: 0.1698 - val_loss: 0.1663 - val_mse: 0.0496 - val_mae: 0.1663\n",
            "Epoch 55/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1695 - mse: 0.0467 - mae: 0.1695 - val_loss: 0.1661 - val_mse: 0.0495 - val_mae: 0.1661\n",
            "Epoch 56/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1691 - mse: 0.0465 - mae: 0.1691 - val_loss: 0.1656 - val_mse: 0.0491 - val_mae: 0.1656\n",
            "Epoch 57/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1688 - mse: 0.0464 - mae: 0.1688 - val_loss: 0.1655 - val_mse: 0.0491 - val_mae: 0.1655\n",
            "Epoch 58/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1685 - mse: 0.0463 - mae: 0.1685 - val_loss: 0.1650 - val_mse: 0.0488 - val_mae: 0.1650\n",
            "Epoch 59/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1683 - mse: 0.0462 - mae: 0.1683 - val_loss: 0.1643 - val_mse: 0.0484 - val_mae: 0.1643\n",
            "Epoch 60/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1681 - mse: 0.0462 - mae: 0.1681 - val_loss: 0.1641 - val_mse: 0.0483 - val_mae: 0.1641\n",
            "Epoch 61/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1678 - mse: 0.0460 - mae: 0.1678 - val_loss: 0.1639 - val_mse: 0.0482 - val_mae: 0.1639\n",
            "Epoch 62/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1675 - mse: 0.0459 - mae: 0.1675 - val_loss: 0.1635 - val_mse: 0.0480 - val_mae: 0.1635\n",
            "Epoch 63/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1674 - mse: 0.0459 - mae: 0.1674 - val_loss: 0.1635 - val_mse: 0.0480 - val_mae: 0.1635\n",
            "Epoch 64/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1670 - mse: 0.0457 - mae: 0.1670 - val_loss: 0.1628 - val_mse: 0.0475 - val_mae: 0.1628\n",
            "Epoch 65/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1669 - mse: 0.0457 - mae: 0.1669 - val_loss: 0.1625 - val_mse: 0.0474 - val_mae: 0.1625\n",
            "Epoch 66/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1667 - mse: 0.0456 - mae: 0.1667 - val_loss: 0.1623 - val_mse: 0.0473 - val_mae: 0.1623\n",
            "Epoch 67/200\n",
            "464/464 [==============================] - 8s 16ms/step - loss: 0.1663 - mse: 0.0454 - mae: 0.1663 - val_loss: 0.1623 - val_mse: 0.0472 - val_mae: 0.1623\n",
            "Epoch 68/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1661 - mse: 0.0454 - mae: 0.1661 - val_loss: 0.1617 - val_mse: 0.0470 - val_mae: 0.1617\n",
            "Epoch 69/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1660 - mse: 0.0453 - mae: 0.1660 - val_loss: 0.1615 - val_mse: 0.0469 - val_mae: 0.1615\n",
            "Epoch 70/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1658 - mse: 0.0452 - mae: 0.1658 - val_loss: 0.1608 - val_mse: 0.0465 - val_mae: 0.1608\n",
            "Epoch 71/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.1654 - mse: 0.0451 - mae: 0.1654 - val_loss: 0.1611 - val_mse: 0.0466 - val_mae: 0.1611\n",
            "Epoch 72/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1653 - mse: 0.0450 - mae: 0.1653 - val_loss: 0.1607 - val_mse: 0.0464 - val_mae: 0.1607\n",
            "Epoch 73/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1650 - mse: 0.0449 - mae: 0.1650 - val_loss: 0.1601 - val_mse: 0.0461 - val_mae: 0.1601\n",
            "Epoch 74/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.1649 - mse: 0.0449 - mae: 0.1649 - val_loss: 0.1598 - val_mse: 0.0460 - val_mae: 0.1598\n",
            "Epoch 75/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1647 - mse: 0.0448 - mae: 0.1647 - val_loss: 0.1597 - val_mse: 0.0458 - val_mae: 0.1597\n",
            "Epoch 76/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1644 - mse: 0.0447 - mae: 0.1644 - val_loss: 0.1594 - val_mse: 0.0456 - val_mae: 0.1594\n",
            "Epoch 77/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1643 - mse: 0.0446 - mae: 0.1643 - val_loss: 0.1595 - val_mse: 0.0457 - val_mae: 0.1595\n",
            "Epoch 78/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1642 - mse: 0.0446 - mae: 0.1642 - val_loss: 0.1592 - val_mse: 0.0456 - val_mae: 0.1592\n",
            "Epoch 79/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.1638 - mse: 0.0445 - mae: 0.1638 - val_loss: 0.1591 - val_mse: 0.0455 - val_mae: 0.1591\n",
            "Epoch 80/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.1637 - mse: 0.0444 - mae: 0.1637 - val_loss: 0.1586 - val_mse: 0.0453 - val_mae: 0.1586\n",
            "Epoch 81/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1635 - mse: 0.0444 - mae: 0.1635 - val_loss: 0.1584 - val_mse: 0.0451 - val_mae: 0.1584\n",
            "Epoch 82/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1633 - mse: 0.0443 - mae: 0.1633 - val_loss: 0.1586 - val_mse: 0.0453 - val_mae: 0.1586\n",
            "Epoch 83/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1633 - mse: 0.0443 - mae: 0.1633 - val_loss: 0.1579 - val_mse: 0.0448 - val_mae: 0.1579\n",
            "Epoch 84/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1632 - mse: 0.0442 - mae: 0.1632 - val_loss: 0.1580 - val_mse: 0.0449 - val_mae: 0.1580\n",
            "Epoch 85/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1629 - mse: 0.0441 - mae: 0.1629 - val_loss: 0.1573 - val_mse: 0.0446 - val_mae: 0.1573\n",
            "Epoch 86/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.1626 - mse: 0.0440 - mae: 0.1626 - val_loss: 0.1571 - val_mse: 0.0444 - val_mae: 0.1571\n",
            "Epoch 87/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1626 - mse: 0.0439 - mae: 0.1626 - val_loss: 0.1574 - val_mse: 0.0446 - val_mae: 0.1574\n",
            "Epoch 88/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1626 - mse: 0.0439 - mae: 0.1626 - val_loss: 0.1569 - val_mse: 0.0442 - val_mae: 0.1569\n",
            "Epoch 89/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1622 - mse: 0.0438 - mae: 0.1622 - val_loss: 0.1566 - val_mse: 0.0441 - val_mae: 0.1566\n",
            "Epoch 90/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1621 - mse: 0.0437 - mae: 0.1621 - val_loss: 0.1561 - val_mse: 0.0438 - val_mae: 0.1561\n",
            "Epoch 91/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1620 - mse: 0.0437 - mae: 0.1620 - val_loss: 0.1566 - val_mse: 0.0442 - val_mae: 0.1566\n",
            "Epoch 92/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1618 - mse: 0.0437 - mae: 0.1618 - val_loss: 0.1563 - val_mse: 0.0439 - val_mae: 0.1563\n",
            "Epoch 93/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1617 - mse: 0.0436 - mae: 0.1617 - val_loss: 0.1563 - val_mse: 0.0439 - val_mae: 0.1563\n",
            "Epoch 94/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1614 - mse: 0.0435 - mae: 0.1614 - val_loss: 0.1558 - val_mse: 0.0437 - val_mae: 0.1558\n",
            "Epoch 95/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1613 - mse: 0.0435 - mae: 0.1613 - val_loss: 0.1558 - val_mse: 0.0436 - val_mae: 0.1558\n",
            "Epoch 96/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1611 - mse: 0.0434 - mae: 0.1611 - val_loss: 0.1555 - val_mse: 0.0435 - val_mae: 0.1555\n",
            "Epoch 97/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1610 - mse: 0.0434 - mae: 0.1610 - val_loss: 0.1556 - val_mse: 0.0436 - val_mae: 0.1556\n",
            "Epoch 98/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1608 - mse: 0.0433 - mae: 0.1608 - val_loss: 0.1554 - val_mse: 0.0436 - val_mae: 0.1554\n",
            "Epoch 99/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1608 - mse: 0.0433 - mae: 0.1608 - val_loss: 0.1546 - val_mse: 0.0431 - val_mae: 0.1546\n",
            "Epoch 100/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1606 - mse: 0.0432 - mae: 0.1606 - val_loss: 0.1550 - val_mse: 0.0432 - val_mae: 0.1550\n",
            "Epoch 101/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1604 - mse: 0.0431 - mae: 0.1604 - val_loss: 0.1549 - val_mse: 0.0432 - val_mae: 0.1549\n",
            "Epoch 102/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1603 - mse: 0.0431 - mae: 0.1603 - val_loss: 0.1548 - val_mse: 0.0431 - val_mae: 0.1548\n",
            "Epoch 103/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1601 - mse: 0.0430 - mae: 0.1601 - val_loss: 0.1546 - val_mse: 0.0431 - val_mae: 0.1546\n",
            "Epoch 104/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1601 - mse: 0.0430 - mae: 0.1601 - val_loss: 0.1540 - val_mse: 0.0427 - val_mae: 0.1540\n",
            "Epoch 105/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1599 - mse: 0.0429 - mae: 0.1599 - val_loss: 0.1541 - val_mse: 0.0428 - val_mae: 0.1541\n",
            "Epoch 106/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1597 - mse: 0.0429 - mae: 0.1597 - val_loss: 0.1537 - val_mse: 0.0426 - val_mae: 0.1537\n",
            "Epoch 107/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1598 - mse: 0.0429 - mae: 0.1598 - val_loss: 0.1541 - val_mse: 0.0427 - val_mae: 0.1541\n",
            "Epoch 108/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1596 - mse: 0.0428 - mae: 0.1596 - val_loss: 0.1541 - val_mse: 0.0427 - val_mae: 0.1541\n",
            "Epoch 109/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1593 - mse: 0.0427 - mae: 0.1593 - val_loss: 0.1536 - val_mse: 0.0425 - val_mae: 0.1536\n",
            "Epoch 110/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1592 - mse: 0.0426 - mae: 0.1592 - val_loss: 0.1528 - val_mse: 0.0420 - val_mae: 0.1528\n",
            "Epoch 111/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1592 - mse: 0.0426 - mae: 0.1592 - val_loss: 0.1531 - val_mse: 0.0422 - val_mae: 0.1531\n",
            "Epoch 112/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1590 - mse: 0.0426 - mae: 0.1590 - val_loss: 0.1534 - val_mse: 0.0424 - val_mae: 0.1534\n",
            "Epoch 113/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1590 - mse: 0.0426 - mae: 0.1590 - val_loss: 0.1528 - val_mse: 0.0421 - val_mae: 0.1528\n",
            "Epoch 114/200\n",
            "464/464 [==============================] - 8s 16ms/step - loss: 0.1588 - mse: 0.0425 - mae: 0.1588 - val_loss: 0.1531 - val_mse: 0.0421 - val_mae: 0.1531\n",
            "Epoch 115/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1586 - mse: 0.0425 - mae: 0.1586 - val_loss: 0.1525 - val_mse: 0.0420 - val_mae: 0.1525\n",
            "Epoch 116/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1586 - mse: 0.0425 - mae: 0.1586 - val_loss: 0.1526 - val_mse: 0.0421 - val_mae: 0.1526\n",
            "Epoch 117/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1583 - mse: 0.0423 - mae: 0.1583 - val_loss: 0.1524 - val_mse: 0.0419 - val_mae: 0.1524\n",
            "Epoch 118/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1583 - mse: 0.0423 - mae: 0.1583 - val_loss: 0.1523 - val_mse: 0.0419 - val_mae: 0.1523\n",
            "Epoch 119/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1582 - mse: 0.0423 - mae: 0.1582 - val_loss: 0.1522 - val_mse: 0.0417 - val_mae: 0.1522\n",
            "Epoch 120/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1580 - mse: 0.0422 - mae: 0.1580 - val_loss: 0.1517 - val_mse: 0.0415 - val_mae: 0.1517\n",
            "Epoch 121/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1580 - mse: 0.0422 - mae: 0.1580 - val_loss: 0.1521 - val_mse: 0.0416 - val_mae: 0.1521\n",
            "Epoch 122/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1579 - mse: 0.0422 - mae: 0.1579 - val_loss: 0.1518 - val_mse: 0.0416 - val_mae: 0.1518\n",
            "Epoch 123/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1577 - mse: 0.0421 - mae: 0.1577 - val_loss: 0.1521 - val_mse: 0.0417 - val_mae: 0.1521\n",
            "Epoch 124/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1575 - mse: 0.0420 - mae: 0.1575 - val_loss: 0.1517 - val_mse: 0.0415 - val_mae: 0.1517\n",
            "Epoch 125/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1575 - mse: 0.0420 - mae: 0.1575 - val_loss: 0.1514 - val_mse: 0.0414 - val_mae: 0.1514\n",
            "Epoch 126/200\n",
            "464/464 [==============================] - 8s 16ms/step - loss: 0.1573 - mse: 0.0420 - mae: 0.1573 - val_loss: 0.1515 - val_mse: 0.0415 - val_mae: 0.1515\n",
            "Epoch 127/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1572 - mse: 0.0419 - mae: 0.1572 - val_loss: 0.1515 - val_mse: 0.0414 - val_mae: 0.1515\n",
            "Epoch 128/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1572 - mse: 0.0419 - mae: 0.1572 - val_loss: 0.1511 - val_mse: 0.0412 - val_mae: 0.1511\n",
            "Epoch 129/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1570 - mse: 0.0418 - mae: 0.1570 - val_loss: 0.1510 - val_mse: 0.0411 - val_mae: 0.1510\n",
            "Epoch 130/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1569 - mse: 0.0418 - mae: 0.1569 - val_loss: 0.1512 - val_mse: 0.0412 - val_mae: 0.1512\n",
            "Epoch 131/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1569 - mse: 0.0418 - mae: 0.1569 - val_loss: 0.1507 - val_mse: 0.0410 - val_mae: 0.1507\n",
            "Epoch 132/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1567 - mse: 0.0417 - mae: 0.1567 - val_loss: 0.1505 - val_mse: 0.0409 - val_mae: 0.1505\n",
            "Epoch 133/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1566 - mse: 0.0417 - mae: 0.1566 - val_loss: 0.1504 - val_mse: 0.0409 - val_mae: 0.1504\n",
            "Epoch 134/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1565 - mse: 0.0416 - mae: 0.1565 - val_loss: 0.1504 - val_mse: 0.0408 - val_mae: 0.1504\n",
            "Epoch 135/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1565 - mse: 0.0416 - mae: 0.1565 - val_loss: 0.1500 - val_mse: 0.0406 - val_mae: 0.1500\n",
            "Epoch 136/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1563 - mse: 0.0416 - mae: 0.1563 - val_loss: 0.1504 - val_mse: 0.0409 - val_mae: 0.1504\n",
            "Epoch 137/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1564 - mse: 0.0416 - mae: 0.1564 - val_loss: 0.1502 - val_mse: 0.0408 - val_mae: 0.1502\n",
            "Epoch 138/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1562 - mse: 0.0415 - mae: 0.1562 - val_loss: 0.1495 - val_mse: 0.0404 - val_mae: 0.1495\n",
            "Epoch 139/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1560 - mse: 0.0414 - mae: 0.1560 - val_loss: 0.1499 - val_mse: 0.0406 - val_mae: 0.1499\n",
            "Epoch 140/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1559 - mse: 0.0414 - mae: 0.1559 - val_loss: 0.1497 - val_mse: 0.0405 - val_mae: 0.1497\n",
            "Epoch 141/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1558 - mse: 0.0414 - mae: 0.1558 - val_loss: 0.1497 - val_mse: 0.0404 - val_mae: 0.1497\n",
            "Epoch 142/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1556 - mse: 0.0413 - mae: 0.1556 - val_loss: 0.1498 - val_mse: 0.0405 - val_mae: 0.1498\n",
            "Epoch 143/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1556 - mse: 0.0413 - mae: 0.1556 - val_loss: 0.1495 - val_mse: 0.0404 - val_mae: 0.1495\n",
            "Epoch 144/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1554 - mse: 0.0412 - mae: 0.1554 - val_loss: 0.1493 - val_mse: 0.0404 - val_mae: 0.1493\n",
            "Epoch 145/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1555 - mse: 0.0412 - mae: 0.1555 - val_loss: 0.1492 - val_mse: 0.0401 - val_mae: 0.1492\n",
            "Epoch 146/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1553 - mse: 0.0411 - mae: 0.1553 - val_loss: 0.1495 - val_mse: 0.0405 - val_mae: 0.1495\n",
            "Epoch 147/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1554 - mse: 0.0412 - mae: 0.1554 - val_loss: 0.1491 - val_mse: 0.0402 - val_mae: 0.1491\n",
            "Epoch 148/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1551 - mse: 0.0411 - mae: 0.1551 - val_loss: 0.1487 - val_mse: 0.0400 - val_mae: 0.1487\n",
            "Epoch 149/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1549 - mse: 0.0410 - mae: 0.1549 - val_loss: 0.1486 - val_mse: 0.0399 - val_mae: 0.1486\n",
            "Epoch 150/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1550 - mse: 0.0410 - mae: 0.1550 - val_loss: 0.1485 - val_mse: 0.0399 - val_mae: 0.1485\n",
            "Epoch 151/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1547 - mse: 0.0409 - mae: 0.1547 - val_loss: 0.1486 - val_mse: 0.0399 - val_mae: 0.1486\n",
            "Epoch 152/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1548 - mse: 0.0409 - mae: 0.1548 - val_loss: 0.1487 - val_mse: 0.0400 - val_mae: 0.1487\n",
            "Epoch 153/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1547 - mse: 0.0409 - mae: 0.1547 - val_loss: 0.1485 - val_mse: 0.0399 - val_mae: 0.1485\n",
            "Epoch 154/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1545 - mse: 0.0408 - mae: 0.1545 - val_loss: 0.1486 - val_mse: 0.0400 - val_mae: 0.1486\n",
            "Epoch 155/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1544 - mse: 0.0408 - mae: 0.1544 - val_loss: 0.1482 - val_mse: 0.0397 - val_mae: 0.1482\n",
            "Epoch 156/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1544 - mse: 0.0407 - mae: 0.1544 - val_loss: 0.1481 - val_mse: 0.0397 - val_mae: 0.1481\n",
            "Epoch 157/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1541 - mse: 0.0407 - mae: 0.1541 - val_loss: 0.1481 - val_mse: 0.0397 - val_mae: 0.1481\n",
            "Epoch 158/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1540 - mse: 0.0406 - mae: 0.1540 - val_loss: 0.1474 - val_mse: 0.0394 - val_mae: 0.1474\n",
            "Epoch 159/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1539 - mse: 0.0406 - mae: 0.1539 - val_loss: 0.1479 - val_mse: 0.0396 - val_mae: 0.1479\n",
            "Epoch 160/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1538 - mse: 0.0405 - mae: 0.1538 - val_loss: 0.1477 - val_mse: 0.0395 - val_mae: 0.1477\n",
            "Epoch 161/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1539 - mse: 0.0406 - mae: 0.1539 - val_loss: 0.1475 - val_mse: 0.0395 - val_mae: 0.1475\n",
            "Epoch 162/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1536 - mse: 0.0404 - mae: 0.1536 - val_loss: 0.1469 - val_mse: 0.0391 - val_mae: 0.1469\n",
            "Epoch 163/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1534 - mse: 0.0403 - mae: 0.1534 - val_loss: 0.1472 - val_mse: 0.0392 - val_mae: 0.1472\n",
            "Epoch 164/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1535 - mse: 0.0404 - mae: 0.1535 - val_loss: 0.1473 - val_mse: 0.0393 - val_mae: 0.1473\n",
            "Epoch 165/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1534 - mse: 0.0403 - mae: 0.1534 - val_loss: 0.1473 - val_mse: 0.0393 - val_mae: 0.1473\n",
            "Epoch 166/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1533 - mse: 0.0403 - mae: 0.1533 - val_loss: 0.1469 - val_mse: 0.0391 - val_mae: 0.1469\n",
            "Epoch 167/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1530 - mse: 0.0401 - mae: 0.1530 - val_loss: 0.1464 - val_mse: 0.0388 - val_mae: 0.1464\n",
            "Epoch 168/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1530 - mse: 0.0401 - mae: 0.1530 - val_loss: 0.1466 - val_mse: 0.0389 - val_mae: 0.1466\n",
            "Epoch 169/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1528 - mse: 0.0401 - mae: 0.1528 - val_loss: 0.1459 - val_mse: 0.0386 - val_mae: 0.1459\n",
            "Epoch 170/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1528 - mse: 0.0401 - mae: 0.1528 - val_loss: 0.1465 - val_mse: 0.0390 - val_mae: 0.1465\n",
            "Epoch 171/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1526 - mse: 0.0400 - mae: 0.1526 - val_loss: 0.1462 - val_mse: 0.0387 - val_mae: 0.1462\n",
            "Epoch 172/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1525 - mse: 0.0399 - mae: 0.1525 - val_loss: 0.1459 - val_mse: 0.0386 - val_mae: 0.1459\n",
            "Epoch 173/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1523 - mse: 0.0399 - mae: 0.1523 - val_loss: 0.1456 - val_mse: 0.0385 - val_mae: 0.1456\n",
            "Epoch 174/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1522 - mse: 0.0398 - mae: 0.1522 - val_loss: 0.1457 - val_mse: 0.0385 - val_mae: 0.1457\n",
            "Epoch 175/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1521 - mse: 0.0397 - mae: 0.1521 - val_loss: 0.1455 - val_mse: 0.0383 - val_mae: 0.1455\n",
            "Epoch 176/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1520 - mse: 0.0397 - mae: 0.1520 - val_loss: 0.1453 - val_mse: 0.0383 - val_mae: 0.1453\n",
            "Epoch 177/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1518 - mse: 0.0396 - mae: 0.1518 - val_loss: 0.1452 - val_mse: 0.0382 - val_mae: 0.1452\n",
            "Epoch 178/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1517 - mse: 0.0396 - mae: 0.1517 - val_loss: 0.1453 - val_mse: 0.0384 - val_mae: 0.1453\n",
            "Epoch 179/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1516 - mse: 0.0395 - mae: 0.1516 - val_loss: 0.1448 - val_mse: 0.0380 - val_mae: 0.1448\n",
            "Epoch 180/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1515 - mse: 0.0394 - mae: 0.1515 - val_loss: 0.1450 - val_mse: 0.0381 - val_mae: 0.1450\n",
            "Epoch 181/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1513 - mse: 0.0393 - mae: 0.1513 - val_loss: 0.1447 - val_mse: 0.0379 - val_mae: 0.1447\n",
            "Epoch 182/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1512 - mse: 0.0393 - mae: 0.1512 - val_loss: 0.1444 - val_mse: 0.0379 - val_mae: 0.1444\n",
            "Epoch 183/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1508 - mse: 0.0391 - mae: 0.1508 - val_loss: 0.1439 - val_mse: 0.0376 - val_mae: 0.1439\n",
            "Epoch 184/200\n",
            "464/464 [==============================] - 9s 19ms/step - loss: 0.1508 - mse: 0.0391 - mae: 0.1508 - val_loss: 0.1442 - val_mse: 0.0377 - val_mae: 0.1442\n",
            "Epoch 185/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1507 - mse: 0.0391 - mae: 0.1507 - val_loss: 0.1436 - val_mse: 0.0375 - val_mae: 0.1436\n",
            "Epoch 186/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1506 - mse: 0.0390 - mae: 0.1506 - val_loss: 0.1436 - val_mse: 0.0375 - val_mae: 0.1436\n",
            "Epoch 187/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1504 - mse: 0.0389 - mae: 0.1504 - val_loss: 0.1431 - val_mse: 0.0372 - val_mae: 0.1431\n",
            "Epoch 188/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1502 - mse: 0.0388 - mae: 0.1502 - val_loss: 0.1432 - val_mse: 0.0372 - val_mae: 0.1432\n",
            "Epoch 189/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1502 - mse: 0.0388 - mae: 0.1502 - val_loss: 0.1431 - val_mse: 0.0371 - val_mae: 0.1431\n",
            "Epoch 190/200\n",
            "464/464 [==============================] - 7s 14ms/step - loss: 0.1499 - mse: 0.0387 - mae: 0.1499 - val_loss: 0.1427 - val_mse: 0.0370 - val_mae: 0.1427\n",
            "Epoch 191/200\n",
            "464/464 [==============================] - 7s 15ms/step - loss: 0.1497 - mse: 0.0386 - mae: 0.1497 - val_loss: 0.1428 - val_mse: 0.0371 - val_mae: 0.1428\n",
            "Epoch 192/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.1495 - mse: 0.0385 - mae: 0.1495 - val_loss: 0.1426 - val_mse: 0.0369 - val_mae: 0.1426\n",
            "Epoch 193/200\n",
            "464/464 [==============================] - 9s 18ms/step - loss: 0.1495 - mse: 0.0385 - mae: 0.1495 - val_loss: 0.1422 - val_mse: 0.0368 - val_mae: 0.1422\n",
            "Epoch 194/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1492 - mse: 0.0383 - mae: 0.1492 - val_loss: 0.1421 - val_mse: 0.0367 - val_mae: 0.1421\n",
            "Epoch 195/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1493 - mse: 0.0384 - mae: 0.1493 - val_loss: 0.1421 - val_mse: 0.0367 - val_mae: 0.1421\n",
            "Epoch 196/200\n",
            "464/464 [==============================] - 8s 16ms/step - loss: 0.1490 - mse: 0.0382 - mae: 0.1490 - val_loss: 0.1419 - val_mse: 0.0366 - val_mae: 0.1419\n",
            "Epoch 197/200\n",
            "464/464 [==============================] - 7s 16ms/step - loss: 0.1488 - mse: 0.0382 - mae: 0.1488 - val_loss: 0.1414 - val_mse: 0.0364 - val_mae: 0.1414\n",
            "Epoch 198/200\n",
            "464/464 [==============================] - 8s 17ms/step - loss: 0.1487 - mse: 0.0381 - mae: 0.1487 - val_loss: 0.1410 - val_mse: 0.0362 - val_mae: 0.1410\n",
            "Epoch 199/200\n",
            "464/464 [==============================] - 8s 18ms/step - loss: 0.1486 - mse: 0.0381 - mae: 0.1486 - val_loss: 0.1408 - val_mse: 0.0361 - val_mae: 0.1408\n",
            "Epoch 200/200\n",
            "464/464 [==============================] - 9s 19ms/step - loss: 0.1484 - mse: 0.0380 - mae: 0.1484 - val_loss: 0.1412 - val_mse: 0.0363 - val_mae: 0.1412\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "model.compile(optimizer= OPTIMIZER, \n",
        "              loss=LOSS_FN,\n",
        "              metrics=[\"mse\", \"mae\"])\n",
        "\n",
        "model = tf.keras.models.load_model(os.path.join(KERAS_DIR, LOG_NAME))\n",
        "LOG_NAME += \"-I\"\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCH)\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_ppV-Ls6b0y"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, save=False):\n",
        "    # Extract the loss, MAE, and MSE values from the history object\n",
        "    loss = history.history['loss']\n",
        "    mse = history.history['mse']\n",
        "    mae = history.history['mae']\n",
        "    val_loss = history.history['val_loss']\n",
        "    val_mse = history.history['val_mse']\n",
        "    val_mae = history.history['val_mae']\n",
        "\n",
        "    # Create a figure and set up the subplots\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(9, 3))\n",
        "\n",
        "    # Plot the loss history\n",
        "    plt.title(REMARK)\n",
        "    ax1.plot(loss, label='Loss')\n",
        "    ax1.plot(val_loss, label='Val Loss')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    # Plot the MSE history\n",
        "    ax2.plot(mse, label='MSE')\n",
        "    ax2.plot(val_mse, label='Val MSE')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('MSE')\n",
        "    ax2.legend()\n",
        "\n",
        "    # Plot the MAE history\n",
        "    ax3.plot(mae, label='MAE')\n",
        "    ax3.plot(val_mae, label='Val MAE')\n",
        "    ax3.set_xlabel('Epochs')\n",
        "    ax3.set_ylabel('MAE')\n",
        "    ax3.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    if (save):\n",
        "        if (not os.path.exists(os.path.join(PLOT_DIR, LOG_NAME))):\n",
        "            plt.savefig(os.path.join(PLOT_DIR, LOG_NAME))\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "uZKCc_zA6b0y",
        "outputId": "000f1cc0-cca1-4775-ba9d-3dc5a821d2dc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x300 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_history(history, save=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcNEeSLn6b0y"
      },
      "source": [
        "### Evaluation with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSNAswWw6b0y",
        "outputId": "fcb7f48c-9ed5-45cb-d7fc-9f0a3a0bec87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 6s 7ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.5127208 ],\n",
              "       [0.84990144],\n",
              "       [0.78687394],\n",
              "       ...,\n",
              "       [0.40798843],\n",
              "       [0.48654518],\n",
              "       [0.65246576]], dtype=float32)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_predict = model.predict(test_dataset)\n",
        "test_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3HTlJ9Sz6b0z",
        "outputId": "3bd26e97-daf0-4c94-a7da-4b41e912a528"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>real</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.512721</td>\n",
              "      <td>0.236462</td>\n",
              "      <td>0.276258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.849901</td>\n",
              "      <td>0.236462</td>\n",
              "      <td>0.613439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.786874</td>\n",
              "      <td>0.836462</td>\n",
              "      <td>0.049588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.926467</td>\n",
              "      <td>0.636462</td>\n",
              "      <td>0.290005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.412648</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.587352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24658</th>\n",
              "      <td>0.509629</td>\n",
              "      <td>0.436462</td>\n",
              "      <td>0.073167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24659</th>\n",
              "      <td>0.970558</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.029442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24660</th>\n",
              "      <td>0.407988</td>\n",
              "      <td>0.636462</td>\n",
              "      <td>0.228474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24661</th>\n",
              "      <td>0.486545</td>\n",
              "      <td>0.836462</td>\n",
              "      <td>0.349917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24662</th>\n",
              "      <td>0.652466</td>\n",
              "      <td>0.836462</td>\n",
              "      <td>0.183997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24663 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       predicted      real     error\n",
              "0       0.512721  0.236462  0.276258\n",
              "1       0.849901  0.236462  0.613439\n",
              "2       0.786874  0.836462  0.049588\n",
              "3       0.926467  0.636462  0.290005\n",
              "4       0.412648  1.000000  0.587352\n",
              "...          ...       ...       ...\n",
              "24658   0.509629  0.436462  0.073167\n",
              "24659   0.970558  1.000000  0.029442\n",
              "24660   0.407988  0.636462  0.228474\n",
              "24661   0.486545  0.836462  0.349917\n",
              "24662   0.652466  0.836462  0.183997\n",
              "\n",
              "[24663 rows x 3 columns]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels = get_label(test_dataset)\n",
        "compare_test = pd.concat([pd.DataFrame(test_predict, columns=[\"predicted\"]), \n",
        "                     pd.DataFrame(test_labels, columns=[\"real\"])], axis=1)\n",
        "\n",
        "compare_test[\"error\"] = abs(compare_test[\"predicted\"] - compare_test[\"real\"])\n",
        "\n",
        "compare_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Aj27AgIK6b0z",
        "outputId": "512b6c4b-13c8-4e6c-c04b-be0be6b7870c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>real</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.512721</td>\n",
              "      <td>0.236462</td>\n",
              "      <td>0.276258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.849901</td>\n",
              "      <td>0.236462</td>\n",
              "      <td>0.613439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.926467</td>\n",
              "      <td>0.636462</td>\n",
              "      <td>0.290005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.412648</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.587352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.520166</td>\n",
              "      <td>0.636462</td>\n",
              "      <td>0.116296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24656</th>\n",
              "      <td>0.694037</td>\n",
              "      <td>0.236462</td>\n",
              "      <td>0.457575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24657</th>\n",
              "      <td>0.299770</td>\n",
              "      <td>0.436462</td>\n",
              "      <td>0.136693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24660</th>\n",
              "      <td>0.407988</td>\n",
              "      <td>0.636462</td>\n",
              "      <td>0.228474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24661</th>\n",
              "      <td>0.486545</td>\n",
              "      <td>0.836462</td>\n",
              "      <td>0.349917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24662</th>\n",
              "      <td>0.652466</td>\n",
              "      <td>0.836462</td>\n",
              "      <td>0.183997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19331 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       predicted      real     error\n",
              "0       0.512721  0.236462  0.276258\n",
              "1       0.849901  0.236462  0.613439\n",
              "3       0.926467  0.636462  0.290005\n",
              "4       0.412648  1.000000  0.587352\n",
              "7       0.520166  0.636462  0.116296\n",
              "...          ...       ...       ...\n",
              "24656   0.694037  0.236462  0.457575\n",
              "24657   0.299770  0.436462  0.136693\n",
              "24660   0.407988  0.636462  0.228474\n",
              "24661   0.486545  0.836462  0.349917\n",
              "24662   0.652466  0.836462  0.183997\n",
              "\n",
              "[19331 rows x 3 columns]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare_test[compare_test[\"error\"] > 1e-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtZDYD7KInYN",
        "outputId": "fc8e8d93-1b34-42d4-f9b1-1385d9e4f660"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.28912680779390915"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare_test[\"error\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAsiIuPT6b00"
      },
      "source": [
        "## Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuvKUV2I6b00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: log/model/savedmodel/recommender-smote-simple\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: log/model/savedmodel/recommender-smote-simple\\assets\n"
          ]
        }
      ],
      "source": [
        "if (not os.path.exists(os.path.join(MODEL_DIR, LOG_NAME))):\n",
        "    tf.saved_model.save(model, os.path.join(MODEL_DIR, LOG_NAME))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbR05q6a6b00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: log/model/keras/recommender-smote-simple\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: log/model/keras/recommender-smote-simple\\assets\n"
          ]
        }
      ],
      "source": [
        "if (not os.path.exists(os.path.join(KERAS_DIR, LOG_NAME))):\n",
        "    model.save(os.path.join(KERAS_DIR, LOG_NAME))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3icvT0z-6b00"
      },
      "outputs": [],
      "source": [
        "def serialize(obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        raise TypeError(\"Object of type {} is not JSON serializable\".format(type(obj)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS0MacWU6b00"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import timedelta\n",
        "\n",
        "log = {\n",
        "    \"name\": LOG_NAME,\n",
        "    \"training_time\": str(timedelta(training_time)),\n",
        "    \"remark\": REMARK,\n",
        "    \"test_error\": compare_test[\"error\"].mean(),\n",
        "    \"results\": {\n",
        "        \"last_loss\": history.history[\"loss\"][-1],\n",
        "        \"last_mae\": history.history[\"mae\"][-1],\n",
        "        \"last_mse\": history.history[\"mse\"][-1],\n",
        "        \"last_val_loss\": history.history[\"val_loss\"][-1],\n",
        "        \"last_val_mae\": history.history[\"val_mae\"][-1],\n",
        "        \"last_val_mse\": history.history[\"val_mse\"][-1],\n",
        "    },\n",
        "    \"hyperparameter\": {\n",
        "        \"learning_rate\": LEARNING_RATE,\n",
        "        \"epoch\": EPOCH,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"loss_func\": tf.keras.losses.serialize(LOSS_FN)[\"class_name\"],\n",
        "        \"optimizer\": tf.keras.optimizers.serialize(OPTIMIZER)[\"class_name\"],\n",
        "    },\n",
        "    # \"data_distribution\": {\n",
        "    #     \"positive\": POSITIVE_SIZE,\n",
        "    #     \"negative\": NEGATIVE_SIZE,\n",
        "    #     \"training_pos\": TRAIN_POS_SIZE,\n",
        "    #     \"training_neg\": TRAIN_NEG_SIZE,\n",
        "    # },\n",
        "    \"data_example\": {\n",
        "        \"influencer\": df_influencer.head().to_dict(),\n",
        "        \"owner\": df_own_norm.head().to_dict(),\n",
        "        \"history\": df_history.head().to_dict(),\n",
        "    },\n",
        "    \"eval\": {\n",
        "        \"loss\": history.history[\"loss\"],\n",
        "        \"mae\": history.history[\"mae\"],\n",
        "        \"mse\": history.history[\"mse\"],\n",
        "        \"val_loss\": history.history[\"val_loss\"],\n",
        "        \"val_mae\": history.history[\"val_mae\"],\n",
        "        \"val_mse\": history.history[\"val_mse\"],\n",
        "    }\n",
        "}\n",
        "if (not os.path.exists(os.path.join(DETAIL_DIR, LOG_NAME + \".json\"))):\n",
        "    with open(os.path.join(DETAIL_DIR, LOG_NAME + '.json'), 'w') as json_file:\n",
        "        log = json.dumps(log, default=serialize)\n",
        "        json_file.write(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuIJ-9tD6b00",
        "outputId": "46695dc1-cd73-4aa8-e8d4-b63b44853a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inf_feature (InputLayer)       [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " own_feature (InputLayer)       [(None, 24)]         0           []                               \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 64)           23104       ['inf_feature[0][0]']            \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)      (None, 64)           22848       ['own_feature[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_2 (TFOpLa  (None, 64)          0           ['sequential_2[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_3 (TFOpLa  (None, 64)          0           ['sequential_3[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_2[0][0]', \n",
            "                                                                  'tf.math.l2_normalize_3[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 45,952\n",
            "Trainable params: 45,952\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "summary = model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtEaCtRk6b00"
      },
      "outputs": [],
      "source": [
        "from contextlib import redirect_stdout\n",
        "\n",
        "with open(os.path.join(SUMMARY_DIR, LOG_NAME + \".txt\"), 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        print(\"Influencer Model:\")\n",
        "        model_influencer.summary()\n",
        "        \n",
        "        print(\"\\nOwner Model:\")\n",
        "        model_owner.summary()\n",
        "        \n",
        "        print(\"\\nFull Model:\")\n",
        "        model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMvdAcM66b01"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4735e28f7f627569bc07f7dc41131ed5d08a93f3d94f12e74778d501b659619"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
